{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50abff7a-a067-48bc-906a-d11cc010a0cf",
   "metadata": {},
   "source": [
    "## 多卡训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5c02d6-e2cf-4ecb-be5a-39a6b6daacfa",
   "metadata": {},
   "source": [
    "### 几个基础概念"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119664e7-4f18-41cf-aa8c-a561d7334748",
   "metadata": {},
   "source": [
    "- **world_size**: 总进程数，一般一张卡对应一个进程\n",
    "- **global_rank**: 当前进程相对全部进程的编号\n",
    "- **local_rank**: 当前进程相对本机进程的编号\n",
    "- **node**: 节点，就是一台服务器\n",
    "- **node_rank**: 当前节点编号\n",
    "- **nproc_per_node**: 每个节点上启动几个进程，一般与节点上的GPU数一致\n",
    "- **master_addr**: 主节点地址\n",
    "- **master_port**: 主节点端口\n",
    "- **group**: 一个进程组，一般一个训练任务对应一个进程组"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2065a0b6-0c0e-497a-925e-c423d5b70391",
   "metadata": {},
   "source": [
    "<img src=\"multi-card.png\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb738fd-322b-4403-8051-e70399cdc3b7",
   "metadata": {},
   "source": [
    "### PyTorch 训练代码样例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a48a551-42ae-4ec5-9eb3-11009f7e56c4",
   "metadata": {},
   "source": [
    "初始化训练环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45cb6e2-d6dd-4115-bfe7-bd6ae91dfda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.distributed.init_process_group(\n",
    "    backend=\"nccl\", #通信后端，nccl, mpi, gloo （建议GPU训练用nccl，CPU训练用gloo）\n",
    "    init_method=None, #前进程组初始化方式。默认为 env://，表示从环境变量读取 MASTER_ADDR, MASTER_PORT, WORLD_SIZE 和 RANK。\n",
    "    timeout=default_pg_timeout,\n",
    "    world_size=-1,\n",
    "    rank=-1,\n",
    "    store=None,\n",
    "    group_name=''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2afb0f7-aad4-4e13-a68f-f4a709838a4f",
   "metadata": {},
   "source": [
    "加载模型和数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce125db3-a61f-4e69-83d1-3edb79a5653e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "dataset = your_dataset()\n",
    "datasampler = DistributedSampler(dataset, num_replicas=world_size, rank=rank)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size_per_gpu, sampler=datasampler)\n",
    "model = your_model()\n",
    "model = DDP(model, device_ids=[local_rank], output_device=local_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f141ba-a5b1-4d7d-8998-ac98a1fbb066",
   "metadata": {},
   "source": [
    "其它部分跟单机单卡训练一致"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaa0e69-80ae-4b66-862a-a7e3668f6de5",
   "metadata": {},
   "source": [
    "### Huggingface 训练 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079f52c5-4be2-4188-8567-10df4dcfdf54",
   "metadata": {},
   "source": [
    "上述步骤 Huggingface 的 Trainer 会自动帮你适配环境，代码与单机单卡训练一致。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71347256-93e4-475a-8a0d-e92ffd449510",
   "metadata": {},
   "source": [
    "### 启动训练（PyTorch原生）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a97bd68-3b64-48c6-af2e-4774b90c1b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在 node0 上运行\n",
    "torchrun --nproc_per_node=4 \\\r\n",
    "         --nnodes=2 \\\r\n",
    "         --node_rank=0  \\ \r\n",
    "         --master_addr=\"192.0.0.1\" \\\r\n",
    "         --master_port=1234 \\\r\n",
    "      ain_no --more_args_for_training_scriptde.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3ee0ac-0097-4b95-8373-c733bf2d1be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在 node1 上运行\n",
    "torchrun --nproc_per_node=4 \\\r\n",
    "         --nnodes=2 \\\r\n",
    "         --node_ran1=0  \\ \r\n",
    "         --master_addr=\"192.0.0.1\" \\\r\n",
    "         --master_port=12\n",
    "         train.py n_no --more_args_for_training_sde.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6498f3f2-2f54-4e3f-b1ab-8d889f5b7c70",
   "metadata": {},
   "source": [
    "### DeepSpeed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d5e600-f782-49d6-bd71-9568330994c9",
   "metadata": {},
   "source": [
    "DeepSpeed 是一个由微软开发的开源深度学习优化库，旨在提高大规模模型训练的效率和可扩展性。\n",
    "\n",
    "它通过多种技术手段来加速训练，包括模型并行化、梯度累积、动态精度缩放、本地模式混合精度等。\n",
    "\n",
    "DeepSpeed 还提供了一些辅助工具，如分布式训练管理、内存优化和模型压缩等，以帮助开发者更好地管理和优化大规模深度学习训练任务。\n",
    "\n",
    "此外，DeepSpeed 基于 PyTorch 构建，只需要简单修改即可迁移。DeepSpeed 已经在许多大规模深度学习项目中得到了应用，包括语言模型、图像分类、目标检测等等。\n",
    "\n",
    "项目地址：https://github.com/microsoft/DeepSpeed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2b88de-b991-4ff6-99c6-b81734c92c2d",
   "metadata": {},
   "source": [
    "**启动训练**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce9ef6a-d814-451d-b7e6-1e0ab6b3a62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepspeed --hostfile=hostfile.txt train.py \\\n",
    "          --deepspeed \\\n",
    "          --deepspeed_config deepspeed_config.json \\\n",
    "          --more_args_for_training_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea30ac3e-2fbe-4478-9701-7360bd43074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hostfile.txt\n",
    "\n",
    "192.168.0.1 slots=4\n",
    "192.168.0.2 slots=4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f4e6ed-0cb3-483e-ab60-29b538b18d8f",
   "metadata": {},
   "source": [
    "### 进程间数据同步：torch.distributed.barrier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e6bc58-b0cf-4f4f-ba05-33b0f6016d68",
   "metadata": {},
   "source": [
    "PyTorch在分布式训练过程中，对于数据的读取是采用主进程预读取并缓存，然后其它进程从缓存中读取，不同进程之间的数据同步具体通过torch.distributed.barrier()实现。\n",
    "\n",
    "torch.distributed.barrier() 意味着设置一个阻塞栅栏，让此进程处于等待状态，等待所有进程到达栅栏处。\n",
    "\n",
    "所有进程都到达了当前的栅栏处，这样所有进程就达到了同步，并同时得到释放。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a06b31-aa57-4b9e-b07a-42a33a8a7749",
   "metadata": {},
   "source": [
    "以上节课的选修代码为例：[12-fine-tuning-02/pretraining/pretrain_gpt2.py](../12-fine-tuning-02/pretraining/pretrain_gpt2.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a145c4f-6de9-4b87-b663-757be32af51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.distributed.get_rank() > 0:\n",
    "    # 主进程加载数据，其它进程等待从缓存加载 arrow 文件\n",
    "    torch.distributed.barrier()\n",
    "\n",
    "tokenized_train_dataset = raw_train_dataset.map(\n",
    "    prepare_train_features,\n",
    "    batched=True,\n",
    "    num_proc=num_proc\n",
    ")\n",
    "\n",
    "tokenized_valid_dataset = raw_valid_dataset.map(\n",
    "    prepare_train_features,\n",
    "    batched=True,\n",
    "    num_proc=num_proc\n",
    ")\n",
    "\n",
    "if torch.distributed.get_rank() == 0:\n",
    "    # 主进程加载数据结束\n",
    "    torch.distributed.barrier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0db0663-4e38-4ecc-afce-f5455993d922",
   "metadata": {},
   "source": [
    "## RLHF 简介"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c5624d-cdef-42aa-985b-0a37a9fed040",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>思考</b>\n",
    "<ol>\n",
    "    <li>RLHF 与 Fine-Tuning 在最终得到效果上有什么不同？</li>\n",
    "    <li>RLHF 与 Fine-Tuning 在数据要求上有什么不同？</li>\n",
    "    <li>所以，什么时候我们需要 RLHF ？</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6de15ab-4438-460f-8996-4875e9321523",
   "metadata": {},
   "source": [
    "Reinforcement Learning from Human Feedback 使用强化学习的方式直接优化带有人类反馈的语言模型。\n",
    "\n",
    "RLHF 使得在一般文本数据语料库上训练的语言模型能和**复杂的人类价值观对齐**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ccf291-169c-4f9c-9e55-bc2c75ab8fe0",
   "metadata": {},
   "source": [
    "### RLHF 的数据形式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baabe60-851f-4b7f-8152-099b68b3082e",
   "metadata": {},
   "source": [
    "- 偏好标注数据：即 Human Feedback，用于训练 Reward Model\n",
    "  - 一些开源数据集\n",
    "     - https://huggingface.co/datasets/Anthropic/hh-rlhf\n",
    "     - https://huggingface.co/datasets/nvidia/HelpSteer\n",
    "     - https://huggingface.co/datasets/HuggingFaceH4/stack-exchange-preferences\n",
    "     - https://huggingface.co/datasets/PKU-Alignment/PKU-SafeRLHF\n",
    "     - https://huggingface.co/datasets/lmsys/chatbot_arena_conversations\n",
    "     - https://huggingface.co/datasets/OpenAssistant/oasst1\n",
    "- Prompt数据：无标注，用于训练 RL，可以直接从 instruction 数据中采样"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fdaaa9-cba1-43f4-9663-e5b9218a7609",
   "metadata": {},
   "source": [
    "### RLHF 的训练过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4147e4-fce3-479b-8b1b-6356b8d697ae",
   "metadata": {},
   "source": [
    "1. **预训练语言模型**\n",
    "\n",
    "这里也可以用额外的标注文本或者条件对这个 LLM 进行微调，但不是必须步骤。\n",
    "\n",
    "<img src=\"pretraining.png\" width=600px>\n",
    "\n",
    "2. **训练奖励模型**\n",
    "\n",
    "<img src=\"reward-model.png\" width=600px>\n",
    "\n",
    "关于模型选择方面，奖励模型（Reward Model, RM）可以是另一个经过微调的 LLM，也可以是根据偏好数据从头开始训练的 LLM。\n",
    "\n",
    "例如： \n",
    "- OpenAI 使用了 175B 的 LLM 和 6B 的 RM；\n",
    "- Anthropic 使用的 LLM 和 RM 从 10B 到 52B 大小不等；\n",
    "- DeepMind 使用了 70B 的 Chinchilla 模型分别作为 LLM 和 RM。\n",
    "\n",
    "3. **RLHF**\n",
    "\n",
    "<img src=\"rlhf.png\" width=600px>\n",
    "\n",
    "这个过程有很多变体，例如:\n",
    "\n",
    "- DeepMind 使用的事 A2C 算法做 RL: https://huggingface.co/blog/deep-rl-a2c\n",
    "- Anthropic 尝试了将 RM 和 LLM 同时优化: https://arxiv.org/abs/2204.05862\n",
    "- Llama 2 引入了2个独立的 RM 分别评估 helpfulness 和 safety；同时在 RL 之前加入 拒绝采样 让一个模型针对同一个 Prompt 生成 K 个答案，然后利用 RM 为这 K 个答案打分，选出最优的答案，再去对原本的模型进行 SFT，以增广模型的探索空间。https://arxiv.org/abs/2307.09288"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062cb0ba-a8e6-4521-96ef-4489a9773ae8",
   "metadata": {},
   "source": [
    "### RLHF 的训练框架"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac165f7-3e00-4bea-a6bf-37da106103b2",
   "metadata": {},
   "source": [
    "- **Trlx**： https://github.com/CarperAI/trlx\n",
    "  - 优点：使用广泛，实现了 OpenAI 的算法\n",
    "  - 缺点：据说代码较乱，不支持 GLM\n",
    "- **DeepspeedChat**：https://github.com/microsoft/DeepSpeedExamples/tree/master/applications/DeepSpeed-Chat\n",
    "  - 优点：深度整合 DeepSpeed，支持 100B 以上模型训练\n",
    "  - 缺点：只支持BLOOM，GPT，Llama2等几种网络结构\n",
    "- **ColossalAI-Chat**：https://github.com/hpcaitech/ColossalAI/tree/main/applications/Chat\n",
    "  - 优点：国产，代码质量高\n",
    "  - 缺点：生态一般"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
