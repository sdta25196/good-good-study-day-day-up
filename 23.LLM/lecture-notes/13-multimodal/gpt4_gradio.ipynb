{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "374278d7",
   "metadata": {},
   "source": [
    "## GPT4v实战：API调用、使用场景实践"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9b1b37",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>注意：</b>\n",
    "<p>由于网络原因下面代码务必在自己的电脑上运行，才能看到界面</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2240c2a2",
   "metadata": {},
   "source": [
    "## 步骤 1：安装所需依赖的包\n",
    "\n",
    "确保你已经安装了 Python，并使用 pip 安装 Gradio 和 OpenAI：\n",
    "\n",
    "#### 如果在本地电脑执行下面命令\n",
    "\n",
    "```\n",
    "pip  install gradio openai\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c12c38",
   "metadata": {},
   "source": [
    "## 如果在实验室执行下面命令"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4145874",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install gradio==3.50  # 在实验室运行时执行的代码，本地不需要"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559039ff",
   "metadata": {},
   "source": [
    "下面代码创建了一个 Gradio 用户界面，可以在文本框中输入问题，并上传最多三张图像。\n",
    "这些输入将传递给 query_gpt4_vision 函数，该函数使用 OpenAI GPT-4 Vision 模型生成对问题的回答。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a45cbb7",
   "metadata": {},
   "source": [
    "## 步骤 2：编写 Gradio 与 GPT-4 Vision 应用\n",
    "在你的 Python 脚本中，编写 Gradio 应用。以下是一个例子，使用 GPT-4 Vision 模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55b5749e-2180-4575-921a-480e0f1b029f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7869\n",
      "Running on public URL: https://62d99b2b9b7ac48c57.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://62d99b2b9b7ac48c57.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "from PIL import Image\n",
    "import io, os\n",
    "\n",
    "# Function to encode the image to base64\n",
    "def encode_image_to_base64(image):\n",
    "    buffered = io.BytesIO()\n",
    "    image.save(buffered, format=\"JPEG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "\n",
    "# Function to query GPT-4 Vision\n",
    "def query_gpt4_vision(text, image1, image2, image3):\n",
    "    client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "    messages = [{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": text}]}]\n",
    "\n",
    "    images = [image1, image2, image3]\n",
    "    for image in images:\n",
    "        if image is not None:\n",
    "            base64_image = encode_image_to_base64(image)\n",
    "            image_message = {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}\n",
    "            }\n",
    "            messages[0][\"content\"].append(image_message)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-vision-preview\",\n",
    "        messages=messages,\n",
    "        max_tokens=1024,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=query_gpt4_vision,\n",
    "    inputs=[\n",
    "        gr.components.Textbox(lines=2, placeholder=\"Enter your question here...\"),\n",
    "        gr.components.Image(type=\"pil\", label=\"Upload Image 1\", tool=\"editor\"),\n",
    "        gr.components.Image(type=\"pil\", label=\"Upload Image 2\", tool=\"editor\"),\n",
    "        gr.components.Image(type=\"pil\", label=\"Upload Image 3\", tool=\"editor\")\n",
    "    ],\n",
    "    outputs=\"text\",\n",
    ")\n",
    "\n",
    "iface.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba8a19c",
   "metadata": {},
   "source": [
    "## 步骤 3：运行 Gradio 应用\n",
    "保存并运行你的 Python 脚本。这将启动 Gradio 用户界面，并在终端中显示本地运行的 URL（通常是 http://127.0.0.1:7860）。访问该 URL 即可查看和使用你的 Gradio 应用。\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>建议：</b>\n",
    "<li>确保你的机器上已经安装了必要的 Python 包。</li>\n",
    "<li> 如果使用 OpenAI 模型，确保你已经设置了正确的 API 密钥。 </li>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d35267",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8063afad-6b39-4a67-8885-57931e7236a8",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "- 菜品价格预估：估算一下这桌子菜的价格，给出每道菜的市场价格。假设这是北京的一家中档餐厅\n",
    "- figure理解：请生成这张图片的caption\n",
    "- 网页设计：生成下面设计图对应的网站源码\n",
    "- 视觉结合知识的推断：根据图中信息，猜测这是什么型号的GPU？请列出所有可能的GPU型号，并给出你的判断依据。猜测大致的生产年限"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5daeb844-eb3d-409b-8be6-f23de1267e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_694/2316504215.py:44: GradioUnusedKwargWarning: You have unused kwarg parameters in Textbox, please remove them: {'update': True}\n",
      "  outputs=gr.components.Text(update=True),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7870\n",
      "Running on public URL: https://af55d50cc065a1923a.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://af55d50cc065a1923a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "from PIL import Image\n",
    "import io, os\n",
    "\n",
    "# Function to encode the image to base64\n",
    "def encode_image_to_base64(image):\n",
    "    buffered = io.BytesIO()\n",
    "    image.save(buffered, format=\"JPEG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "\n",
    "# Function to query GPT-4 Vision\n",
    "def query_gpt4_vision(*inputs):\n",
    "    client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "    messages = [{\"role\": \"user\", \"content\": []}]\n",
    "\n",
    "    for input_item in inputs:\n",
    "        if isinstance(input_item, str):  # Text input\n",
    "            messages[0][\"content\"].append({\"type\": \"text\", \"text\": input_item})\n",
    "        elif isinstance(input_item, Image.Image):  # Image input\n",
    "            base64_image = encode_image_to_base64(input_item)\n",
    "            messages[0][\"content\"].append({\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}\n",
    "            })\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-vision-preview\",\n",
    "        messages=messages,\n",
    "        max_tokens=1024,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Dynamically generate input components\n",
    "input_components = []\n",
    "for i in range(2):  # Change this number to add more inputs\n",
    "    input_components.append(gr.components.Textbox(lines=2, placeholder=f\"Enter your text input {i+1}...\"))\n",
    "    input_components.append(gr.components.Image(type=\"pil\", label=f\"Upload Image {i+1}\", tool=\"editor\"))\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=query_gpt4_vision,\n",
    "    inputs=input_components,\n",
    "    outputs=gr.components.Text(update=True), \n",
    ")\n",
    "\n",
    "iface.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc09939-2aaa-456a-ada6-ac8c69b33cdd",
   "metadata": {},
   "source": [
    "- 具身智能场景：\n",
    "  假设你是一个机器人，在厨房从事工作，你会执行的操作包括  靠近(物体坐标)， 抓取(物体坐标),  移动(开始坐标，结束坐标)，这里的坐标需要根据你的视觉系统来估计xy位置，以及深度信息z。人类会给你指令，你需要按照人类指令要求的完成对应的操作。比如，人类：把抽屉里的绿色包装袋拿出来。此时你看到的画面是这样的：\n",
    "  请问接下来你该执行什么指令？只给出指令即可，但是需要包括具体的坐标信息（假设当前画面的长宽为单位1，使用你估计的深度信息以及xy偏移位置）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00320ab-8cb2-4dae-8646-31fb095d9ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
