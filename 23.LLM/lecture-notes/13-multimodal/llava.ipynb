{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aecbb605-ac5a-4e2e-82c1-33235a9c6307",
   "metadata": {},
   "source": [
    "# LLaVA模型训练\n",
    "\n",
    "LLaVA模型的训练分为两个主要阶段：\n",
    "- 特征对齐的预训练。只更新特征映射矩阵\n",
    "- 端到端微调。特征投影矩阵和LLM都进行更新\n",
    "\n",
    "![LLaVA训练过程](img/llava.PNG)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4a28aad-ca80-4539-bbd1-5d9c9b76bfda",
   "metadata": {},
   "source": [
    "## 阶段一：图文特征对齐预训练\n",
    "\n",
    "基本数据格式：\n",
    "```JSON\n",
    "{\n",
    "    \"id\": \"任意一个非重复id，例如 0888888\",\n",
    "    \"image\": \",\n",
    "    \"conversations\": [\n",
    "      {\n",
    "        \"from\": \"human\",\n",
    "        \"value\": \"请简要描述这幅图像.\\n<image>\"\n",
    "      },\n",
    "      {\n",
    "        \"from\": \"gpt\",\n",
    "        \"value\": \"这张图片中显示了一名男子骑自行车和一列正在行驶的火车。前台的男子穿着深色上衣和裤子，看起来有亚洲面孔，他正骑着一辆深色自行车，从左向右穿过画面，并且与镜头形成了接近正面的视角。他的表情专注，似乎正在前往某个目的地。\r\n",
    "\r\n",
    "在他的后方，可以看到一列红色和白色相间的高速火车，火车车身上有几个窗户，火车上方有电网。火车左边的树木使得场景给人一种自然的氛围。在图片的左上角部分，还有一个路牌，上面有日文和英文的混合文本，但具体内容不清晰。整个场景是在室外拍摄的，光线来自自然光，可能是在傍晚或清晨，因为阳光有点斜射到场景中。\r\n",
    "\r\n",
    "整体上，这张照片创造了一种行驶中的火车与骑自行车的人共同构成的动态场面，可能在日本的城市郊外或者乡村地区拍摄。。\"\n",
    "      }\n",
    "    ]\n",
    "},\n",
    "```\n",
    "\n",
    "下载[LLaVA预训练数据集](https://huggingface.co/datasets/liuhaotian/LLaVA-Pretrain)\n",
    "\n",
    "### 开始训练\n",
    "- 8x A100 (80GB) 耗时5.5h\r",
    "- 基于DeepSpeed ZeRO2 \r",
    "- 输入图像分辨率336 px \r",
    "- 训练参数：特征映射层结构（2层全连接层)\n",
    "\n",
    "训练脚本 [`pretrain.sh`](https://github.com/haotian-liu/LLaVA/blob/main/scripts/v1_5/pretrain.h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37f093b-a73f-4588-ac6d-641afb1fdf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "deepspeed llava/train/train_mem.py \\\n",
    "    --deepspeed ./scripts/zero2.json \\\n",
    "    --model_name_or_path lmsys/vicuna-13b-v1.5 \\\n",
    "    --version plain \\\n",
    "    --data_path ./playground/data/LLaVA-Pretrain/blip_laion_cc_sbu_558k.json \\\n",
    "    --image_folder ./playground/data/LLaVA-Pretrain/images \\\n",
    "    --vision_tower openai/clip-vit-large-patch14-336 \\\n",
    "    --mm_projector_type mlp2x_gelu \\\n",
    "    --tune_mm_mlp_adapter True \\\n",
    "    --mm_vision_select_layer -2 \\\n",
    "    --mm_use_im_start_end False \\\n",
    "    --mm_use_im_patch_token False \\\n",
    "    --bf16 True \\\n",
    "    --output_dir ./checkpoints/llava-v1.5-13b-pretrain \\\n",
    "    --num_train_epochs 1 \\\n",
    "    --per_device_train_batch_size 32 \\\n",
    "    --per_device_eval_batch_size 4 \\\n",
    "    --gradient_accumulation_steps 1 \\\n",
    "    --evaluation_strategy \"no\" \\\n",
    "    --save_strategy \"steps\" \\\n",
    "    --save_steps 24000 \\\n",
    "    --save_total_limit 1 \\\n",
    "    --learning_rate 1e-3 \\\n",
    "    --weight_decay 0. \\\n",
    "    --warmup_ratio 0.03 \\\n",
    "    --lr_scheduler_type \"cosine\" \\\n",
    "    --logging_steps 1 \\\n",
    "    --tf32 True \\\n",
    "    --model_max_length 2048 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --dataloader_num_workers 4 \\\n",
    "    --lazy_preprocess True \\\n",
    "    --report_to wandb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7843668b-b2c2-4fa6-b211-75151a3e11a9",
   "metadata": {},
   "source": [
    "## 阶段二：图-文指令微调训练\n",
    "\n",
    "基本数据格式：\n",
    "```JSON\n",
    "  {\r\n",
    "    \"id\": \"任意一个非重复id，例如 0999999\",\r\n",
    "    \"image\": \"图像文件路径，例如：my_data/hongyadong.jpg \",\r\n",
    "    \"conversations\": [\r\n",
    "      {\r\n",
    "        \"from\": \"human\",\r\n",
    "        \"value\": \"<im图中的男子正在做什么？拍摄于哪里?\"\r\n",
    "      },\r\n",
    "      {\r\n",
    "        \"from\": \"gpt\",\r\n",
    "        图中的男子正在骑自行车，他的视线专注，看起来他正在前往某个目的地。市洪崖洞景区的照片.\"\r\n",
    "      },\r\n",
    "      {\r\n",
    "        \"from\": \"human\",\r\n",
    "        \"value\": \"图中有什么可以识别的文字内容?\"\r\n",
    "      },\r\n",
    "      {\r\n",
    "        \"from\": \"gpt\",\r\n",
    "        “value”: “图片右下角墙体上写着\\”洪崖洞\\“三个字.\"\r\n",
    "      }]\r\n",
    "  },\r\n",
    "\n",
    "```\n",
    "\n",
    "下载LLaVA训练所需文本数据集: [llava_v1_5_mix665k.json](https://huggingface.co/datasets/liuhaotian/LLaVA-Instruct-150K/blob/main/llava_v1_5_mix665k.json)\n",
    "\n",
    "下载LLaVA训练所需图像数据集:\n",
    "- COCO: [train2017](http://images.cocodataset.org/zips/train2017.zip)\n",
    "- GQA: [images](https://downloads.cs.stanford.edu/nlp/data/gqa/images.zip)\n",
    "- OCR-VQA: [download script](https://drive.google.com/drive/folders/1_GYPY5UkUy7HIcR0zq3ZCFgeZN7BAfm_?usp=sharing), **we save all files as `.jpg`**\n",
    "- TextVQA: [train_val_images](https://dl.fbaipublicfiles.com/textvqa/images/train_val_images.zip)\n",
    "- VisualGenome: [part1](https://cs.stanford.edu/people/rak248/VG_100K_2/images.zip), [part2](https://cs.stanford.edu/people/rak248/VG_100K_2/images2.zip)\r\n",
    "\n",
    "### 开始训.练\r",
    "- 8x A100 (80GB) 耗205h\n",
    "- 基于DeepSpeed ZeR32 \n",
    "- 输入图像分辨率336 px \n",
    "- 训练参数：特征映射层结构（2层全连接层以及LLM\n",
    "\n",
    "\n",
    "训练脚本:  [`finetune.sh`](https://github.com/haotian-liu/LLaVA/blob/main/scripts/v1_5/finetune.sh)\n",
    "LoRA训练脚本: [`finetune_lora.sh`](https://github.com/haotian-liu/LLaVA/blob/main/scripts/v1_5/finetune_lora.sh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfb970e-c031-49bc-b965-7c86ea30f1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "deepspeed llava/train/train_mem.py \\\n",
    "    --deepspeed ./scripts/zero3.json \\\n",
    "    --model_name_or_path lmsys/vicuna-13b-v1.5 \\\n",
    "    --version v1 \\\n",
    "    --data_path ./playground/data/llava_v1_5_mix665k.json \\\n",
    "    --image_folder ./playground/data \\\n",
    "    --vision_tower openai/clip-vit-large-patch14-336 \\\n",
    "    --pretrain_mm_mlp_adapter ./checkpoints/llava-v1.5-13b-pretrain/mm_projector.bin \\\n",
    "    --mm_projector_type mlp2x_gelu \\\n",
    "    --mm_vision_select_layer -2 \\\n",
    "    --mm_use_im_start_end False \\\n",
    "    --mm_use_im_patch_token False \\\n",
    "    --image_aspect_ratio pad \\\n",
    "    --group_by_modality_length True \\\n",
    "    --bf16 True \\\n",
    "    --output_dir ./checkpoints/llava-v1.5-13b \\\n",
    "    --num_train_epochs 1 \\\n",
    "    --per_device_train_batch_size 16 \\\n",
    "    --per_device_eval_batch_size 4 \\\n",
    "    --gradient_accumulation_steps 1 \\\n",
    "    --evaluation_strategy \"no\" \\\n",
    "    --save_strategy \"steps\" \\\n",
    "    --save_steps 50000 \\\n",
    "    --save_total_limit 1 \\\n",
    "    --learning_rate 2e-5 \\\n",
    "    --weight_decay 0. \\\n",
    "    --warmup_ratio 0.03 \\\n",
    "    --lr_scheduler_type \"cosine\" \\\n",
    "    --logging_steps 1 \\\n",
    "    --tf32 True \\\n",
    "    --model_max_length 2048 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --dataloader_num_workers 4 \\\n",
    "    --lazy_preprocess True \\\n",
    "    --report_to wandb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
