{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¡ è¿™èŠ‚è¯¾ä¼šå¸¦ç»™ä½ \n",
    "\n",
    "1. äº†è§£æœºå™¨å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µ\n",
    "2. æŒæ¡æ¨¡å‹è®­ç»ƒ/å¾®è°ƒ/å°å‚æ•°é‡å¾®è°ƒçš„æ“ä½œè¿‡ç¨‹\n",
    "3. æŒæ¡æ¨¡å‹å¾®è°ƒ/å°å‚æ•°é‡å¾®è°ƒå…³é”®ã€Œè¶…å‚ã€\n",
    "4. æŒæ¡è®­ç»ƒæ•°æ®çš„é€‰æ‹©ã€å‡†å¤‡ã€æ¸…æ´—ç­‰æ–¹æ³•ä¸æ€è·¯\n",
    "5. è®­ç»ƒä¸€ä¸ªå‚ç›´é¢†åŸŸçš„å¤§æ¨¡å‹\n",
    "\n",
    "å¼€å§‹ä¸Šè¯¾ï¼\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å†™åœ¨å‰é¢\n",
    "\n",
    "1. è¿™ä¸¤å ‚è¯¾å†…å®¹æœ‰éš¾åº¦ï¼Œæ˜¯æ•´é—¨è¯¾é‡Œæœ€éš¾çš„ä¸¤å ‚ï¼ˆæ²¡æœ‰ä¹‹ä¸€ï¼‰\n",
    "   1. æœ‰å¾ˆå¤šé™Œç”Ÿçš„åè¯ï¼ŒåŒ…æ‹¬æ•°å­¦åè¯å’Œæ¨¡å‹ç®—æ³•æœ¬èº«çš„åè¯\n",
    "   2. æ¶‰åŠåˆ°å¾ˆå¤šæ•°å­¦çŸ¥è¯†ï¼Œå¾ˆå¤šä¸œè¥¿æœ¬èº«æ˜¯ä»æ•°å­¦æ¨å¯¼å‡ºæ¥çš„ï¼Œä¸å¥½å…·è±¡åŒ–\n",
    "   3. æ·±åº¦å­¦ä¹ é‡Œæœ‰å¤§é‡åŸºäºç»éªŒçš„æ€»ç»“ï¼Œä½“ç°æˆå„ç§è¶…å‚å’Œ Tricks\n",
    "2. **è¿™å ‚è¯¾è¯¥æ€ä¹ˆå­¦**\n",
    "   1. ä¹‹å‰æ¥è§¦è¿‡æœºå™¨å­¦ä¹ çš„åŒå­¦\n",
    "      - å°½é‡å¤šç†è§£ç†è®ºéƒ¨åˆ†ï¼Œè¡¥å……ä¹‹å‰ç¼ºå¤±çš„çŸ¥è¯†\n",
    "      - æ¯å¤šç†è§£ä¸€ä¸ªçŸ¥è¯†ç‚¹ï¼Œå°±æ¯”åˆ«äººæ›´èµ„æ·±äº†ä¸€ç‚¹\n",
    "   2. ç¼–ç¨‹åŸºç¡€æ‰å®ï¼Œä½†å®Œå…¨æ²¡æ¥è§¦è¿‡æœºå™¨å­¦ä¹ çš„åŒå­¦\n",
    "      - å…ˆå­¦ä¼šæ•´ä¸ªæµç¨‹ï¼Œèƒ½ä¸Šæ‰‹è·‘å®éªŒæ˜¯è‡³å…³é‡è¦çš„ç¬¬ä¸€æ­¥\n",
    "      - å°½é‡ç†è§£ä¸€äº›åŸºæœ¬åŸç†ï¼Œè‡³å°‘æœªæ¥æƒ³è¿›ä¸€æ­¥äº†è§£åŸç†æ—¶çŸ¥é“é‚£ä¸ªé—®é¢˜å’Œä»€ä¹ˆæ¦‚å¿µæœ‰å…³\n",
    "   3. ç¼–ç¨‹ä»ä¸ç†Ÿç»ƒçš„åŒå­¦\n",
    "      - å…ˆå½“ç§‘æ™®ææ–™å¬ï¼Œæ„Ÿå—ä¸€ä¸‹ AI æ¨¡å‹çš„åº•å±‚æ˜¯æ€ä¹ˆå·¥ä½œçš„\n",
    "      - æŠ“ç´§è¡¥å……åŸºç¡€èƒ½åŠ›ï¼Œä¸ç§¯è·¬æ­¥ï¼Œæ— ä»¥è‡³åƒé‡Œ\n",
    "3. æ·±åº¦å­¦ä¹ æ˜¯åŸºäºæ•°å­¦çš„ç»éªŒç§‘å­¦\n",
    "   1. ç¨‹åºå‘˜æ€ç»´ï¼šIF...ELSE... *â€œä½ å°±å‘Šè¯‰æˆ‘é‡åˆ°è¿™ä¸ªæƒ…å†µæ€ä¹ˆåŠâ€*\n",
    "   2. ç®—æ³•å·¥ç¨‹å¸ˆæ€ç»´ï¼š$P(åŠæ³•|æƒ…å†µ)$ *â€œè¿™ä¸ªæƒ…å†µ**å¤§æ¦‚ç‡**ä½ å¯ä»¥**å°è¯•**XXXâ€*\n",
    "4. æ·±åº¦å­¦ä¹ è¿™ä¸ªé¢†åŸŸå°±åƒæ”€ç å³°\n",
    "   1. ä¸å­˜åœ¨æ·å¾„ï¼Œè‡³å°‘ç›®å‰è¿˜æ²¡æœ‰\n",
    "   2. æ ¹æ®è‡ªèº«æ¡ä»¶ï¼Œè§åˆ°é£æ™¯ã€æ”€ä¸Šä¸€åº§å°å³°ã€è¶…è¶Šè‡ªå·±åŸæ¥çš„é«˜åº¦ï¼Œéƒ½æ˜¯æ”¶è·ï¼åŠ æ²¹ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>é¢å‘åˆå­¦è€…çš„æ·±åº¦å­¦ä¹ è¯¾ï¼š</b> \n",
    "<ol>\n",
    "<li>å´æ©è¾¾ã€Šäººäºº AIã€‹(ç‰¹åˆ«é€šä¿—) https://www.zhihu.com/education/video-course/1556316449043668992</li>\n",
    "<li>ææ²çš„æ·±åº¦å­¦ä¹ è¯¾ (ç¨å¾®æ·±ä¸€ç‚¹) https://www.zhihu.com/education/video-course/1647604835598092705</li>\n",
    "</ol>\n",
    "åœ¨è¿™ä¸ªæ›´å¹¿æ³›çš„å®šä½ä¸Šï¼Œå·²ç»æœ‰å¾ˆå¤šä¼˜ç§€çš„è¯¾ç¨‹ã€‚æœ¬è¯¾ç¨‹åªé’ˆå¯¹å¤§æ¨¡å‹å¾®è°ƒçš„çŸ¥è¯†åŸºç¡€å±•å¼€ã€‚\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä»€ä¹ˆæ—¶å€™éœ€è¦ Fine-Tuning\n",
    "\n",
    "1. æœ‰ç§æœ‰éƒ¨ç½²çš„éœ€æ±‚\n",
    "2. å¼€æºæ¨¡å‹åŸç”Ÿçš„èƒ½åŠ›ä¸æ»¡è¶³ä¸šåŠ¡éœ€æ±‚\n",
    "\n",
    "## å…ˆçœ‹ä¸€ä¸ªä¾‹å­"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://localhost:6006/\n",
    "\n",
    "**è®¢é…’åº—æœºå™¨äºº**\n",
    "\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"æ‚¨å¥½ï¼Œæˆ‘è¦æ‰¾ä¸€å®¶èˆ’é€‚å‹é…’åº—ä½å®¿ï¼Œç„¶åå¸Œæœ›é…’åº—æä¾›æš–æ°”ä¸è¡Œæå¯„å­˜ã€‚\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"search\",\n",
    "        \"arguments\": {\n",
    "            \"facilities\": [\n",
    "                \"æš–æ°”\",\n",
    "                \"è¡Œæå¯„å­˜\"\n",
    "            ],\n",
    "            \"type\": \"èˆ’é€‚å‹\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"return\",\n",
    "        \"records\": [\n",
    "            {\n",
    "                \"name\": \"åŒ—äº¬é¦™æ±Ÿæˆ´æ–¯é…’åº—\",\n",
    "                \"type\": \"èˆ’é€‚å‹\",\n",
    "                \"address\": \"åŒ—äº¬ä¸œåŸåŒºå—æ²³æ²¿å¤§è¡—å—æ¹¾å­èƒ¡åŒ1å·\",\n",
    "                \"subway\": \"å¤©å®‰é—¨ä¸œåœ°é“ç«™Bå£\",\n",
    "                \"phone\": \"010-65127788\",\n",
    "                \"facilities\": [\n",
    "                    \"é…’åº—å„å¤„æä¾›wifi\",\n",
    "                    \"å›½é™…é•¿é€”ç”µè¯\",\n",
    "                    \"å¹é£æœº\",\n",
    "                    \"24å°æ—¶çƒ­æ°´\",\n",
    "                    \"æš–æ°”\",\n",
    "                    \"è¥¿å¼é¤å…\",\n",
    "                    \"ä¸­å¼é¤å…\",\n",
    "                    \"æ®‹ç–¾äººè®¾æ–½\",\n",
    "                    \"ä¼šè®®å®¤\",\n",
    "                    \"æ— çƒŸæˆ¿\",\n",
    "                    \"å•†åŠ¡ä¸­å¿ƒ\",\n",
    "                    \"æ—©é¤æœåŠ¡\",\n",
    "                    \"æ¥æœºæœåŠ¡\",\n",
    "                    \"æ¥å¾…å¤–å®¾\",\n",
    "                    \"æ´—è¡£æœåŠ¡\",\n",
    "                    \"è¡Œæå¯„å­˜\",\n",
    "                    \"ç§Ÿè½¦\",\n",
    "                    \"å«é†’æœåŠ¡\"\n",
    "                ],\n",
    "                \"price\": 328.0,\n",
    "                \"rating\": 4.2,\n",
    "                \"hotel_id\": 10\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"é‚£æ¨èæ‚¨åŒ—äº¬é¦™æ±Ÿæˆ´æ–¯é…’åº—ï¼Œç¬¦åˆæ‚¨çš„å…¨éƒ¨ä½å®¿è¦æ±‚å¹¶ä¸”ä»·æ ¼åˆæ¯”è¾ƒåˆé€‚çš„é…’åº—ã€‚\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"è¿™å®¶é…’åº—çš„ä»·æ ¼æ˜¯å¤šå°‘ï¼Ÿ\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"è¿™å®¶é…’åº—çš„ä»·æ ¼æ˜¯æ¯æ™š328.0å…ƒã€‚\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"å¥½çš„ï¼Œé‚£å°±é¢„è®¢åŒ—äº¬é¦™æ±Ÿæˆ´æ–¯é…’åº—å§ï¼\"\n",
    "    },\n",
    "    {\n",
    "       \"role\": \"assistant\",\n",
    "        \"content\": \"å¥½çš„ï¼Œç¥æ‚¨å…¥ä½æ„‰å¿«ï¼\"\n",
    "    }\n",
    "]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä¸€ã€å…ˆæ‰¾æ‰¾æ„Ÿè§‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸Šæ‰‹æ“ä½œä¸€ä¸ªç®€å•çš„ä¾‹å­ï¼š\n",
    "\n",
    "- **æƒ…æ„Ÿåˆ†ç±»**\n",
    "  - è¾“å…¥ï¼šç”µå½±è¯„è®º\n",
    "  - è¾“å‡ºï¼š\\['è´Ÿé¢','æ­£é¢'\\]\n",
    "  - æ•°æ®æºï¼šhttps://huggingface.co/datasets/rotten_tomatoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1ã€**å·¥å…·**ï¼šä»‹ç»ä¸€ä¸ªæ¨¡å‹è®­ç»ƒåˆ©å™¨ Hugging Face\n",
    "\n",
    "- å®˜ç½‘ï¼šhttp://www.huggingface.co\n",
    "- ç›¸å½“äºé¢å‘ NLP æ¨¡å‹çš„ Github\n",
    "- å°¤å…¶åŸºäº transformer çš„å¼€æºæ¨¡å‹éå¸¸å…¨\n",
    "- å°è£…äº†æ¨¡å‹ã€æ•°æ®é›†ã€è®­ç»ƒå™¨ç­‰ï¼Œä½¿æ¨¡å‹çš„ä¸‹è½½ã€ä½¿ç”¨ã€è®­ç»ƒéƒ½éå¸¸æ–¹ä¾¿\n",
    "\n",
    "**å®‰è£…ä¾èµ–**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# pipå®‰è£…\n",
    "pip install transformers # å®‰è£…æœ€æ–°çš„ç‰ˆæœ¬\n",
    "pip install transformers == 4.30 # å®‰è£…æŒ‡å®šç‰ˆæœ¬\n",
    "# condaå®‰è£…\n",
    "conda install -c huggingface transformers  # åª4.0ä»¥åçš„ç‰ˆæœ¬\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2ã€æ“ä½œæµç¨‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "<img src=\"training_process.png\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "<br />\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>æ³¨æ„ï¼š</b> \n",
    "<ul>\n",
    "<li>ä»¥ä¸‹çš„ä»£ç ï¼Œéƒ½ä¸è¦åœ¨Jupyterç¬”è®°ä¸Šç›´æ¥è¿è¡Œï¼Œä¼šæ­»æœºï¼ï¼</li>\n",
    "<li>è¯·ä¸‹è½½å·¦è¾¹çš„è„šæœ¬`experiments/tiny/train.py`ï¼Œåœ¨å®éªŒæœåŠ¡å™¨ä¸Šè¿è¡Œã€‚</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. å¯¼å…¥ç›¸å…³åº“"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import TrainingArguments, Seq2SeqTrainingArguments\n",
    "from transformers import Trainer, Seq2SeqTrainer\n",
    "import transformers\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import TextGenerationPipeline\n",
    "import torch\n",
    "import numpy as np\n",
    "import os, re\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. åŠ è½½**æ•°æ®é›†**\n",
    "\n",
    "é€šè¿‡HuggingFaceï¼Œå¯ä»¥æŒ‡å®šæ•°æ®é›†åç§°ï¼Œè¿è¡Œæ—¶è‡ªåŠ¨ä¸‹è½½"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# æ•°æ®é›†åç§°\n",
    "DATASET_NAME = \"rotten_tomatoes\" \n",
    "\n",
    "# åŠ è½½æ•°æ®é›†\n",
    "raw_datasets = load_dataset(DATASET_NAME)\n",
    "\n",
    "# è®­ç»ƒé›†\n",
    "raw_train_dataset = raw_datasets[\"train\"]\n",
    "\n",
    "# éªŒè¯é›†\n",
    "raw_valid_dataset = raw_datasets[\"validation\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. åŠ è½½**æ¨¡å‹**\n",
    "\n",
    "é€šè¿‡HuggingFaceï¼Œå¯ä»¥æŒ‡å®šæ¨¡å‹åç§°ï¼Œè¿è¡Œæ—¶è‡ªåŠ¨ä¸‹è½½"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# æ¨¡å‹åç§°\n",
    "MODEL_NAME = \"gpt2\" \n",
    "\n",
    "# åŠ è½½æ¨¡å‹ \n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME,trust_remote_code=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. åŠ è½½ **Tokenizer**\n",
    "\n",
    "é€šè¿‡HuggingFaceï¼Œå¯ä»¥æŒ‡å®šæ¨¡å‹åç§°ï¼Œè¿è¡Œæ—¶è‡ªåŠ¨ä¸‹è½½å¯¹åº”Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# åŠ è½½tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME,trust_remote_code=True)\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "tokenizer.pad_token_id = 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "```python\n",
    "# å…¶å®ƒç›¸å…³å…¬å…±å˜é‡èµ‹å€¼\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­ï¼šåŒä¸ªç§å­çš„éšæœºåºåˆ—å¯å¤ç°\n",
    "transformers.set_seed(42)\n",
    "\n",
    "# æ ‡ç­¾é›†\n",
    "named_labels = ['neg','pos']\n",
    "\n",
    "# æ ‡ç­¾è½¬ token_id\n",
    "label_ids = [\n",
    "    tokenizer(named_labels[i],add_special_tokens=False)[\"input_ids\"][0] \n",
    "    for i in range(len(named_labels))\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **å¤„ç†æ•°æ®é›†**ï¼šè½¬æˆæ¨¡å‹æ¥å—çš„è¾“å…¥æ ¼å¼\n",
    "   - æ‹¼æ¥è¾“å…¥è¾“å‡ºï¼š\\<INPUT TOKEN IDS\\>\\<EOS_TOKEN_ID\\>\\<OUTPUT TOKEN IDS\\>\n",
    "   - PADæˆç›¸ç­‰é•¿åº¦ï¼š\n",
    "      - <INPUT 1.1><INPUT 1.2>...\\<EOS_TOKEN_ID\\>\\<OUTPUT TOKEN IDS\\>\\<PAD\\>...\\<PAD\\>\n",
    "      - <INPUT 2.1><INPUT 2.2>...\\<EOS_TOKEN_ID\\>\\<OUTPUT TOKEN IDS\\>\\<PAD\\>...\\<PAD\\>\n",
    "   - æ ‡è¯†å‡ºå‚ä¸ Loss è®¡ç®—çš„ Tokens (åªæœ‰è¾“å‡º Token å‚ä¸ Loss è®¡ç®—)\n",
    "      - \\<-100\\>\\<-100\\>...\\<OUTPUT TOKEN IDS\\>\\<-100\\>...\\<-100\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "MAX_LEN=32   #æœ€å¤§åºåˆ—é•¿åº¦ï¼ˆè¾“å…¥+è¾“å‡ºï¼‰\n",
    "DATA_BODY_KEY = \"text\" # æ•°æ®é›†ä¸­çš„è¾“å…¥å­—æ®µå\n",
    "DATA_LABEL_KEY = \"label\" #æ•°æ®é›†ä¸­è¾“å‡ºå­—æ®µå\n",
    "\n",
    "# å®šä¹‰æ•°æ®å¤„ç†å‡½æ•°ï¼ŒæŠŠåŸå§‹æ•°æ®è½¬æˆinput_ids, attention_mask, labels\n",
    "def process_fn(examples):\n",
    "    model_inputs = {\n",
    "            \"input_ids\": [],\n",
    "            \"attention_mask\": [],\n",
    "            \"labels\": [],\n",
    "        }\n",
    "    for i in range(len(examples[DATA_BODY_KEY])):\n",
    "        inputs = tokenizer(examples[DATA_BODY_KEY][i],add_special_tokens=False)\n",
    "        label = label_ids[examples[DATA_LABEL_KEY][i]]\n",
    "        input_ids = inputs[\"input_ids\"] + [tokenizer.eos_token_id, label]\n",
    "        \n",
    "        raw_len = len(input_ids)\n",
    "        input_len = len(inputs[\"input_ids\"]) + 1\n",
    "\n",
    "        if raw_len >= MAX_LEN:\n",
    "            input_ids = input_ids[-MAX_LEN:]\n",
    "            attention_mask = [1] * MAX_LEN\n",
    "            labels = [-100]*(MAX_LEN - 1) + [label]\n",
    "        else:\n",
    "            input_ids = input_ids + [tokenizer.pad_token_id] * (MAX_LEN - raw_len)\n",
    "            attention_mask = [1] * raw_len + [0] * (MAX_LEN - raw_len)\n",
    "            labels = [-100]*input_len + [label] + [-100] * (MAX_LEN - raw_len)\n",
    "        model_inputs[\"input_ids\"].append(input_ids)\n",
    "        model_inputs[\"attention_mask\"].append(attention_mask)\n",
    "        model_inputs[\"labels\"].append(labels)\n",
    "    return model_inputs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# å¤„ç†è®­ç»ƒæ•°æ®é›†\n",
    "tokenized_train_dataset = raw_train_dataset.map(\n",
    "    process_fn,\n",
    "    batched=True,\n",
    "    remove_columns=raw_train_dataset.columns,\n",
    "    desc=\"Running tokenizer on train dataset\",\n",
    ")\n",
    "\n",
    "# å¤„ç†éªŒè¯æ•°æ®é›†\n",
    "tokenized_valid_dataset = raw_valid_dataset.map(\n",
    "    process_fn,\n",
    "    batched=True,\n",
    "    remove_columns=raw_valid_dataset.columns,\n",
    "    desc=\"Running tokenizer on validation dataset\",\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. å®šä¹‰**æ•°æ®è§„æ•´å™¨**ï¼šè®­ç»ƒæ—¶è‡ªåŠ¨å°†æ•°æ®æ‹†åˆ†æˆ **Batch**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# å®šä¹‰æ•°æ®æ ¡å‡†å™¨ï¼ˆè‡ªåŠ¨ç”Ÿæˆbatchï¼‰\n",
    "collater = DataCollatorWithPadding(\n",
    "    tokenizer=tokenizer, return_tensors=\"pt\",\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. å®šä¹‰è®­ç»ƒ **è¶…å‚**ï¼šæ¯”å¦‚**å­¦ä¹ ç‡**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "LR=2e-5         # å­¦ä¹ ç‡\n",
    "BATCH_SIZE=8    # Batchå¤§å°\n",
    "INTERVAL=100    # æ¯å¤šå°‘æ­¥æ‰“ä¸€æ¬¡ log / åšä¸€æ¬¡ eval\n",
    "\n",
    "# å®šä¹‰è®­ç»ƒå‚æ•°\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./output\",              # checkpointä¿å­˜è·¯å¾„\n",
    "    evaluation_strategy=\"steps\",        # æŒ‰æ­¥æ•°è®¡ç®—evalé¢‘ç‡\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,                 # è®­ç»ƒepochæ•°\n",
    "    per_device_train_batch_size=BATCH_SIZE,     # æ¯å¼ å¡çš„batchå¤§å°\n",
    "    gradient_accumulation_steps=1,              # ç´¯åŠ å‡ ä¸ªstepåšä¸€æ¬¡å‚æ•°æ›´æ–°\n",
    "    per_device_eval_batch_size=BATCH_SIZE,      # evaluation batch size\n",
    "    eval_steps=INTERVAL,                # æ¯Næ­¥evalä¸€æ¬¡\n",
    "    logging_steps=INTERVAL,             # æ¯Næ­¥logä¸€æ¬¡\n",
    "    save_steps=INTERVAL,                # æ¯Næ­¥ä¿å­˜ä¸€ä¸ªcheckpoint\n",
    "    learning_rate=LR,                   # å­¦ä¹ ç‡\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. å®šä¹‰**è®­ç»ƒå™¨**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "```python\n",
    "# èŠ‚çœæ˜¾å­˜\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "# å®šä¹‰è®­ç»ƒå™¨\n",
    "trainer = Trainer(\n",
    "    model=model, # å¾…è®­ç»ƒæ¨¡å‹\n",
    "    args=training_args, # è®­ç»ƒå‚æ•°\n",
    "    data_collator=collater, # æ•°æ®æ ¡å‡†å™¨\n",
    "    train_dataset=tokenized_train_dataset,  # è®­ç»ƒé›†\n",
    "    eval_dataset=tokenized_valid_dataset,   # éªŒè¯é›†\n",
    "    # compute_metrics=compute_metric,         # è®¡ç®—è‡ªå®šä¹‰è¯„ä¼°æŒ‡æ ‡\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. å¼€å§‹è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# å¼€å§‹è®­ç»ƒ\n",
    "trainer.train()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### æ€»ç»“ä¸Šè¿°è¿‡ç¨‹\n",
    "\n",
    "1. åŠ è½½æ•°æ®é›†\n",
    "2. æ•°æ®é¢„å¤„ç†ï¼š\n",
    "   - å°†è¾“å…¥è¾“å‡ºæŒ‰ç‰¹å®šæ ¼å¼æ‹¼æ¥\n",
    "   - æ–‡æœ¬è½¬ Token IDs\n",
    "   - é€šè¿‡ labels æ ‡è¯†å‡ºå“ªéƒ¨åˆ†æ˜¯è¾“å‡ºï¼ˆåªæœ‰è¾“å‡ºçš„ token å‚ä¸ loss è®¡ç®—ï¼‰\n",
    "4. åŠ è½½æ¨¡å‹ã€Tokenizer\n",
    "5. å®šä¹‰æ•°æ®è§„æ•´å™¨\n",
    "6. å®šä¹‰è®­ç»ƒè¶…å‚ï¼šå­¦ä¹ ç‡ã€æ‰¹æ¬¡å¤§å°ã€...\n",
    "7. å®šä¹‰è®­ç»ƒå™¨\n",
    "8. å¼€å§‹è®­ç»ƒ\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>åˆ’é‡ç‚¹ï¼š</b> \n",
    "    <ul>\n",
    "        <li>è®°ä½ä¸Šé¢çš„æµç¨‹ï¼Œä½ å°±èƒ½è·‘é€šæ¨¡å‹è®­ç»ƒè¿‡ç¨‹</li>\n",
    "        <li>ç†è§£ä¸‹é¢çš„çŸ¥è¯†ï¼Œä½ å°±èƒ½è®­ç»ƒå¥½æ¨¡å‹æ•ˆæœ</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## äºŒã€ä»€ä¹ˆæ˜¯æ¨¡å‹\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>å°è¯•ï¼š</b> ç”¨ç®€å•çš„æ•°å­¦è¯­è¨€è¡¨è¾¾æ¦‚å¿µ\n",
    "</div>\n",
    "\n",
    "### 2.1ã€é€šä¿—ï¼ˆä¸ä¸¥è°¨ï¼‰çš„è¯´ã€**æ¨¡å‹**æ˜¯ä¸€ä¸ªå‡½æ•°ï¼š\n",
    "\n",
    "$y=F(x;\\omega)$\n",
    "\n",
    "- å®ƒæ¥æ”¶è¾“å…¥$x$ï¼šå¯ä»¥æ˜¯ä¸€ä¸ªè¯ã€ä¸€ä¸ªå¥å­ã€ä¸€ç¯‡æ–‡ç« æˆ–å›¾ç‰‡ã€è¯­éŸ³ã€è§†é¢‘ ...\n",
    "  - è¿™äº›ç‰©ä½“éƒ½è¢«è¡¨ç¤ºæˆä¸€ä¸ªæ•°å­¦ã€ŒçŸ©é˜µã€ï¼ˆå…¶å®åº”è¯¥å«å¼ é‡ï¼Œtensorï¼‰\n",
    "- å®ƒé¢„æµ‹è¾“å‡º$y$\n",
    "  - å¯ä»¥æ˜¯ã€Œæ˜¯å¦ã€ï¼ˆ{0,1}ï¼‰ã€æ ‡ç­¾ï¼ˆ{0,1,2,3...}ï¼‰ã€ä¸€ä¸ªæ•°å€¼ï¼ˆå›å½’é—®é¢˜ï¼‰ã€ä¸‹ä¸€ä¸ªè¯çš„æ¦‚ç‡ ...\n",
    "- å®ƒçš„è¡¨è¾¾å¼å°±æ˜¯ç½‘ç»œç»“æ„ï¼ˆè¿™é‡Œç‰¹æŒ‡æ·±åº¦å­¦ä¹ ï¼‰\n",
    "- å®ƒæœ‰ä¸€ç»„**å‚æ•°** $\\omega$ï¼Œè¿™å°±æ˜¯æˆ‘ä»¬è¦è®­ç»ƒçš„éƒ¨åˆ†\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>æŠŠå®ƒæƒ³è±¡æˆä¸€ä¸ªæ–¹ç¨‹ï¼š</b> \n",
    "    <ol>\n",
    "        <li>æ¯æ¡æ•°æ®å°±æ˜¯ä¸€å¯¹å„¿ $(x,y)$ ï¼Œå®ƒä»¬æ˜¯å¸¸é‡</li>\n",
    "        <li>å‚æ•°æ˜¯æœªçŸ¥æ•°ï¼Œæ˜¯å˜é‡</li>\n",
    "        <li>$F$ å°±æ˜¯è¡¨è¾¾å¼ï¼šæˆ‘ä»¬ä¸çŸ¥é“çœŸå®çš„å…¬å¼æ˜¯ä»€ä¹ˆæ ·çš„ï¼Œæ‰€ä»¥å‡è®¾äº†ä¸€ä¸ªè¶³å¤Ÿå¤æ‚çš„å…¬å¼ï¼ˆæ¯”å¦‚ï¼Œä¸€ä¸ªç‰¹å®šç»“æ„çš„ç¥ç»ç½‘ç»œï¼‰</li>\n",
    "        <li>è¿™ä¸ªæ±‚è§£è¿™ä¸ªæ–¹ç¨‹ï¼ˆè¿‘ä¼¼è§£ï¼‰å°±æ˜¯è®­ç»ƒè¿‡ç¨‹</li>\n",
    "    </ol>\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>é€šä¿—çš„è®²ï¼š</b> è®­ç»ƒï¼Œå°±æ˜¯ç¡®å®šè¿™ç»„å‚æ•°çš„å–å€¼\n",
    "    <ul>\n",
    "        <li>ç”¨æ•°å­¦ï¼ˆæ•°å€¼åˆ†æï¼‰æ–¹æ³•æ‰¾åˆ°ä½¿æ¨¡å‹åœ¨è®­ç»ƒé›†ä¸Šè¡¨ç°è¶³å¤Ÿå¥½çš„ä¸€ä¸ªå€¼</li>\n",
    "        <li>è¡¨ç°è¶³å¤Ÿå¥½ï¼Œå°±æ˜¯è¯´ï¼Œå¯¹æ¯ä¸ªæ•°æ®æ ·æœ¬$(x,y)$ï¼Œä½¿ $F(x;\\omega)$ çš„å€¼å°½å¯èƒ½æ¥è¿‘ $y$</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "### 2.2ã€ä¸€ä¸ªæœ€ç®€å•çš„ç¥ç»ç½‘ç»œ\n",
    "\n",
    "ä¸€ä¸ªç¥ç»å…ƒï¼š$y=f(\\sum_i w_i\\cdot x_i)$\n",
    "\n",
    "<img src=\"neuron.jpg\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "æŠŠå¾ˆå¤šç¥ç»å…ƒè¿æ¥èµ·æ¥ï¼Œå°±æˆäº†ç¥ç»ç½‘ç»œï¼š$y=f(\\sum_i w_i\\cdot x_i)$ã€$z=f(\\sum_i w'_i\\cdot y_i)$ã€$\\tau=f(\\sum_i w''_i\\cdot z_i)$ã€...\n",
    "\n",
    "<img src=\"network.jpg\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "è¿™é‡Œçš„$f$å«æ¿€æ´»å‡½æ•°ï¼Œæœ‰å¾ˆå¤šç§å½¢å¼\n",
    "\n",
    "ç°ä»Šçš„å¤§æ¨¡å‹ä¸­å¸¸ç”¨çš„æ¿€æ´»å‡½æ•°åŒ…æ‹¬ï¼šReLUã€GELUã€Swish\n",
    "\n",
    "<img src=\"activation.jpeg\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>æ€è€ƒï¼š</b> è¿™é‡Œå¦‚æœæ²¡æœ‰æ¿€æ´»å‡½æ•°ä¼šæ€æ ·ï¼Ÿ\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä¸‰ã€ä»€ä¹ˆæ˜¯æ¨¡å‹è®­ç»ƒ\n",
    "\n",
    "æˆ‘ä»¬å¸Œæœ›æ‰¾åˆ°ä¸€ç»„å‚æ•°$\\omega$ï¼Œä½¿æ¨¡å‹é¢„æµ‹çš„è¾“å‡º$\\hat{y}=F(x;\\omega)$ä¸çœŸå®çš„è¾“å‡º$y$ï¼Œå°½å¯èƒ½çš„æ¥è¿‘\n",
    "\n",
    "è¿™é‡Œï¼Œæˆ‘ä»¬ï¼ˆè‡³å°‘ï¼‰éœ€è¦ä¸¤ä¸ªè¦ç´ ï¼š\n",
    "\n",
    "- ä¸€ä¸ªæ•°æ®é›†ï¼ŒåŒ…å«$N$ä¸ªè¾“å…¥è¾“å‡ºçš„ä¾‹å­ï¼ˆç§°ä¸ºæ ·æœ¬ï¼‰ï¼š$D=\\{(x_i,y_i)\\}_{i=1}^N$\n",
    "- ä¸€ä¸ª**æŸå¤±å‡½æ•°**ï¼Œè¡¡é‡æ¨¡å‹é¢„æµ‹çš„è¾“å‡ºä¸çœŸå®è¾“å‡ºä¹‹é—´çš„å·®è·ï¼š$\\mathrm{loss}(y,F(x;\\omega))$\n",
    "\n",
    "### 3.1ã€æ¨¡å‹è®­ç»ƒæœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªæ±‚è§£æœ€ä¼˜åŒ–é—®é¢˜çš„è¿‡ç¨‹\n",
    "\n",
    "$\\min_{\\omega} L(D,\\omega)$\n",
    "\n",
    "$L(D,\\omega)=\\frac{1}{N}\\sum_{i=1}^N\\mathrm{loss}(y,F(x;\\omega))$\n",
    "\n",
    "### 3.2ã€æ€ä¹ˆæ±‚è§£\n",
    "\n",
    "å›å¿†ä¸€ä¸‹æ¢¯åº¦çš„å®šä¹‰\n",
    "\n",
    "<img src=\"gradient.svg\" style=\"margin-left: 0px\" width=\"400px\">\n",
    "\n",
    "ä»æœ€ç®€å•çš„æƒ…å†µè¯´èµ·ï¼šæ¢¯åº¦ä¸‹é™ä¸å‡¸é—®é¢˜\n",
    "\n",
    "<img src=\"gradient.png\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "æ¢¯åº¦å†³å®šäº†å‡½æ•°å˜åŒ–çš„æ–¹å‘ï¼Œæ¯æ¬¡è¿­ä»£æ›´æ–°æˆ‘ä»¬ä¼šæ”¶æ•›åˆ°ä¸€ä¸ªæå€¼\n",
    "\n",
    "$\\omega_{n+1}\\leftarrow \\omega_n - \\gamma \\nabla_{\\omega}L(D,\\omega)$\n",
    "\n",
    "å…¶ä¸­ï¼Œ$\\gamma<1$å«åš**å­¦ä¹ ç‡**ï¼Œå®ƒå’Œæ¢¯åº¦çš„æ¨¡æ•°å…±åŒå†³å®šäº†æ¯æ­¥èµ°å¤šè¿œ\n",
    "\n",
    "### 3.3ã€**ç°å®æ€»æ˜¯æ²¡é‚£ä¹ˆç®€å•ï¼ˆ1ï¼‰**ï¼šåœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šæ±‚æ¢¯åº¦ï¼Œè®¡ç®—é‡å¤ªå¤§äº†\n",
    "\n",
    "<br/>\n",
    "<img src=\"batch.png\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>ç»éªŒï¼š</b>\n",
    "    <ul>\n",
    "        <li>å¦‚æœå…¨é‡å‚æ•°è®­ç»ƒï¼šæ¡ä»¶å…è®¸çš„æƒ…å†µä¸‹ï¼Œå…ˆå°è¯•Batch Sizeå¤§äº›</li>\n",
    "        <li>å°å‚æ•°é‡å¾®è°ƒï¼šBatch Size å¤§ä¸ä¸€å®šå°±å¥½ï¼Œçœ‹ç¨³å®šæ€§</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "### 3.4ã€**ç°å®æ€»æ˜¯æ²¡é‚£ä¹ˆç®€å•ï¼ˆ2ï¼‰**ï¼šæ·±åº¦å­¦ä¹ æ²¡æœ‰å…¨å±€æœ€ä¼˜è§£ï¼ˆéå‡¸é—®é¢˜ï¼‰\n",
    "\n",
    "<br/>\n",
    "<img src=\"local_minima.png\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "### 3.5ã€**ç°å®æ€»æ˜¯æ²¡é‚£ä¹ˆç®€å•ï¼ˆ3ï¼‰**ï¼šå­¦ä¹ ç‡ä¹Ÿå¾ˆå…³é”®ï¼Œç”šè‡³éœ€è¦åŠ¨æ€è°ƒæ•´\n",
    "\n",
    "<br/>\n",
    "<img src=\"lr.png\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>åˆ’é‡ç‚¹ï¼š</b>é€‚å½“è°ƒæ•´å­¦ä¹ ç‡ï¼ˆLearning Rateï¼‰ï¼Œé¿å…é™·å…¥å¾ˆå·®çš„å±€éƒ¨è§£æˆ–è€…è·³è¿‡äº†å¥½çš„è§£\n",
    "</div>\n",
    "\n",
    "## å››ã€æ±‚è§£å™¨\n",
    "\n",
    "ä¸ºäº†è®©è®­ç»ƒè¿‡ç¨‹æ›´å¥½çš„æ”¶æ•›ï¼Œäººä»¬è®¾è®¡äº†å¾ˆå¤šæ›´å¤æ‚çš„æ±‚è§£å™¨\n",
    "\n",
    "- æ¯”å¦‚ï¼šSGDã€L-BFGSã€Rpropã€RMSpropã€Adamã€AdamWã€AdaGradã€AdaDelta ç­‰ç­‰\n",
    "- ä½†æ˜¯ï¼Œå¥½åœ¨å¯¹äºTransformeræœ€å¸¸ç”¨çš„å°±æ˜¯ Adam æˆ–è€… AdamW\n",
    "\n",
    "## äº”ã€ä¸€äº›å¸¸ç”¨çš„**æŸå¤±å‡½æ•°**\n",
    "\n",
    "- ä¸¤ä¸ªæ•°å€¼çš„å·®è·ï¼ŒMean Squared Errorï¼š$\\ell_{\\mathrm{MSE}}=\\frac{1}{N}\\sum_{i=1}^N(y_i-\\hat{y}_i)^2$ (ç­‰ä»·äºæ¬§å¼è·ç¦»ï¼Œè§ä¸‹æ–‡)\n",
    "- ä¸¤ä¸ªå‘é‡ä¹‹é—´çš„ï¼ˆæ¬§å¼ï¼‰è·ç¦»ï¼š$\\ell(\\mathbf{y},\\mathbf{\\hat{y}})=\\|\\mathbf{y}-\\mathbf{\\hat{y}}\\|$\n",
    "- ä¸¤ä¸ªå‘é‡ä¹‹é—´çš„å¤¹è§’ï¼ˆä½™å¼¦è·ç¦»ï¼‰ï¼š\n",
    "  <img src=\"cosine_loss.png\" style=\"margin-left: 0px\" width=\"400px\">\n",
    "\n",
    "- ä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒä¹‹é—´çš„å·®å¼‚ï¼Œäº¤å‰ç†µï¼š$\\ell_{\\mathrm{CE}}(p,q)=-\\sum_i p_i\\log q_i$ â€”â€”å‡è®¾æ˜¯æ¦‚ç‡åˆ†å¸ƒ p,q æ˜¯ç¦»æ•£çš„\n",
    "- è¿™äº›æŸå¤±å‡½æ•°ä¹Ÿå¯ä»¥ç»„åˆä½¿ç”¨ï¼ˆåœ¨æ¨¡å‹è’¸é¦çš„åœºæ™¯å¸¸è§è¿™ç§æƒ…å†µï¼‰ï¼Œä¾‹å¦‚$L=L_1+\\lambda L_2$ï¼Œå…¶ä¸­$\\lambda$æ˜¯ä¸€ä¸ªé¢„å…ˆå®šä¹‰çš„æƒé‡ï¼Œä¹Ÿå«ä¸€ä¸ªã€Œè¶…å‚ã€\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>æ€è€ƒï¼š</b> ä½ èƒ½æ‰¾åˆ°è¿™äº›æŸå¤±å‡½æ•°å’Œåˆ†ç±»ã€èšç±»ã€å›å½’é—®é¢˜ä¹‹é—´çš„å…³ç³»å—ï¼Ÿ\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å…­ã€å†åŠ¨æ‰‹å¤ä¹ ä¸€ä¸‹ä¸Šè¿°è¿‡ç¨‹\n",
    "\n",
    "ç”¨ PyTorch è®­ç»ƒä¸€ä¸ªæœ€ç®€å•çš„ç¥ç»ç½‘ç»œ\n",
    "\n",
    "æ•°æ®é›†ï¼ˆMNISTï¼‰æ ·ä¾‹ï¼š\n",
    "\n",
    "<img src=\"MNIST.jpg\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "è¾“å…¥ä¸€å¼  28Ã—28 çš„å›¾åƒï¼Œè¾“å‡ºæ ‡ç­¾ 0--9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "TEST_BACTH_SIZE = 1000\n",
    "EPOCHS = 15\n",
    "LR = 0.01\n",
    "SEED = 42\n",
    "LOG_INTERVAL = 100\n",
    "\n",
    "# å®šä¹‰ä¸€ä¸ªå…¨è¿æ¥ç½‘ç»œ\n",
    "class FeedForwardNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # ç¬¬ä¸€å±‚784ç»´è¾“å…¥ã€256ç»´è¾“å‡º -- å›¾åƒå¤§å°28Ã—28=784\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        # ç¬¬äºŒå±‚256ç»´è¾“å…¥ã€128ç»´è¾“å‡º\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        # ç¬¬ä¸‰å±‚128ç»´è¾“å…¥ã€64ç»´è¾“å‡º\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        # ç¬¬å››å±‚64ç»´è¾“å…¥ã€10ç»´è¾“å‡º -- è¾“å‡ºç±»åˆ«10ç±»ï¼ˆ0,1,...9ï¼‰\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "        # Dropout module with 0.2 drop probability\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # æŠŠè¾“å…¥å±•å¹³æˆ1Då‘é‡\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        # æ¯å±‚æ¿€æ´»å‡½æ•°æ˜¯ReLUï¼Œé¢å¤–åŠ dropout\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "\n",
    "        # è¾“å‡ºä¸º10ç»´æ¦‚ç‡åˆ†å¸ƒ\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "# è®­ç»ƒè¿‡ç¨‹\n",
    "def train(model, loss_fn, device, train_loader, optimizer, epoch):\n",
    "    # å¼€å¯æ¢¯åº¦è®¡ç®—\n",
    "    model.train()\n",
    "    for batch_idx, (data_input, true_label) in enumerate(train_loader):\n",
    "        # ä»æ•°æ®åŠ è½½å™¨è¯»å–ä¸€ä¸ªbatch\n",
    "        # æŠŠæ•°æ®ä¸Šè½½åˆ°GPUï¼ˆå¦‚æœ‰ï¼‰\n",
    "        data_input, true_label = data_input.to(device), true_label.to(device)\n",
    "        # æ±‚è§£å™¨åˆå§‹åŒ–ï¼ˆæ¯ä¸ªbatchåˆå§‹åŒ–ä¸€æ¬¡ï¼‰\n",
    "        optimizer.zero_grad()\n",
    "        # æ­£å‘ä¼ æ’­ï¼šæ¨¡å‹ç”±è¾“å…¥é¢„æµ‹è¾“å‡º\n",
    "        output = model(data_input)\n",
    "        # è®¡ç®—loss\n",
    "        loss = loss_fn(output, true_label) \n",
    "        # åå‘ä¼ æ’­ï¼šè®¡ç®—å½“å‰batchçš„lossçš„æ¢¯åº¦\n",
    "        loss.backward()\n",
    "        # ç”±æ±‚è§£å™¨æ ¹æ®æ¢¯åº¦æ›´æ–°æ¨¡å‹å‚æ•°\n",
    "        optimizer.step()\n",
    "\n",
    "        # é—´éš”æ€§çš„è¾“å‡ºå½“å‰batchçš„è®­ç»ƒloss\n",
    "        if batch_idx % LOG_INTERVAL == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data_input), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "# è®¡ç®—åœ¨æµ‹è¯•é›†çš„å‡†ç¡®ç‡å’Œloss\n",
    "def test(model, loss_fn, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            # sum up batch loss\n",
    "            test_loss += loss_fn(output, target, reduction='sum').item()\n",
    "            # get the index of the max log-probability\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "def main():\n",
    "    # æ£€æŸ¥æ˜¯å¦æœ‰GPU\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "\n",
    "    # è®¾ç½®éšæœºç§å­ï¼ˆä»¥ä¿è¯ç»“æœå¯å¤ç°ï¼‰\n",
    "    torch.manual_seed(SEED)\n",
    "\n",
    "    # è®­ç»ƒè®¾å¤‡ï¼ˆGPUæˆ–CPUï¼‰\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    # è®¾ç½®batch size\n",
    "    train_kwargs = {'batch_size': BATCH_SIZE}\n",
    "    test_kwargs = {'batch_size': TEST_BACTH_SIZE}\n",
    "\n",
    "    if use_cuda:\n",
    "        cuda_kwargs = {'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                       'shuffle': True}\n",
    "        train_kwargs.update(cuda_kwargs)\n",
    "        test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "    # æ•°æ®é¢„å¤„ç†ï¼ˆè½¬tensorã€æ•°å€¼å½’ä¸€åŒ–ï¼‰\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    # è‡ªåŠ¨ä¸‹è½½MNISTæ•°æ®é›†\n",
    "    dataset_train = datasets.MNIST('data', train=True, download=True,\n",
    "                                   transform=transform)\n",
    "    dataset_test = datasets.MNIST('data', train=False,\n",
    "                                  transform=transform)\n",
    "\n",
    "    # å®šä¹‰æ•°æ®åŠ è½½å™¨ï¼ˆè‡ªåŠ¨å¯¹æ•°æ®åŠ è½½ã€å¤šçº¿ç¨‹ã€éšæœºåŒ–ã€åˆ’åˆ†batchã€ç­‰ç­‰ï¼‰\n",
    "    train_loader = torch.utils.data.DataLoader(dataset_train, **train_kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset_test, **test_kwargs)\n",
    "\n",
    "    # åˆ›å»ºç¥ç»ç½‘ç»œæ¨¡å‹\n",
    "    model = FeedForwardNet().to(device)\n",
    "\n",
    "    # æŒ‡å®šæ±‚è§£å™¨\n",
    "    optimizer = optim.SGD(model.parameters(), lr=LR)\n",
    "    # scheduler = StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "\n",
    "    # å®šä¹‰losså‡½æ•°\n",
    "    # æ³¨ï¼šnll ä½œç”¨äº log_softmax ç­‰ä»·äºäº¤å‰ç†µï¼Œæ„Ÿå…´è¶£çš„åŒå­¦å¯ä»¥è‡ªè¡Œæ¨å¯¼\n",
    "    # https://blog.csdn.net/weixin_38145317/article/details/103288032\n",
    "    loss_fn = F.nll_loss\n",
    "\n",
    "    # è®­ç»ƒNä¸ªepoch\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        train(model, loss_fn, device, train_loader, optimizer, epoch)\n",
    "        test(model, loss_fn, device, test_loader)\n",
    "        # scheduler.step()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>å¦‚ä½•è¿è¡Œè¿™æ®µä»£ç ï¼š</b>\n",
    "<ol>\n",
    "    <li>ä¸è¦åœ¨Jupyterç¬”è®°ä¸Šç›´æ¥è¿è¡Œ</li>\n",
    "    <li>è¯·å°†å·¦ä¾§çš„ `experiments/mnist/train.py` æ–‡ä»¶ä¸‹è½½åˆ°æœ¬åœ°</li>\n",
    "    <li>å®‰è£…ç›¸å…³ä¾èµ–åŒ…: pip install torch torchvision</li>\n",
    "    <li>è¿è¡Œï¼špython3 train.py</li>\n",
    "</ol>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [é€‰ä¿®å†…å®¹](optional/index.ipynb)\n",
    "\n",
    "æ·±åº¦å­¦ä¹ ä¸­è¿˜æœ‰å¾ˆå¤šå¸¸ç”¨æŠ€å·§ï¼Œæ¶‰åŠçš„èƒŒæ™¯çŸ¥è¯†è¾ƒæ·±ï¼Œä¸åœ¨è¯¾ä¸Šå±•å¼€äº†ã€‚\n",
    "\n",
    "æˆ‘ä»¬é€‰äº†ä¸€äº›æœ€å¸¸ç”¨çš„ï¼Œæ•´ç†æˆäº†éƒ¨åˆ†é€‰ä¿®å†…å®¹ã€‚\n",
    "\n",
    "å»ºè®®æœ‰æ·±å…¥å­¦ä¹ éœ€æ±‚çš„åŒå­¦è‡ªè¡Œé˜…è¯»ï¼Œæœ‰ç–‘é—®çš„å¯ä»¥åœ¨ç¾¤é‡Œæé—®ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä½œä¸š\n",
    "\n",
    "åœ¨ HuggingFace ä¸Šæ‰¾ä¸€ä¸ªç®€å•çš„æ•°æ®é›†ï¼Œè‡ªå·±å®ç°ä¸€ä¸ªè®­ç»ƒè¿‡ç¨‹"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
