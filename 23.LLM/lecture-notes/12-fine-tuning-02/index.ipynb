{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "793358ee-47c2-4b34-a627-6fb49343a47f",
   "metadata": {},
   "source": [
    "## 八、什么是训练/预训练/微调/轻量化微调\n",
    "\n",
    "- 模型训练（Training）\n",
    "- 预训练（Pre-Training）\n",
    "- 微调（Fine-Tuning）\n",
    "- 轻量化微调（Parameter Efficient Fine-Tuning, PEFT）\n",
    "\n",
    "<br/>\n",
    "<img src=\"training.png\" style=\"margin-left: 0px\" width=\"600px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3af1c3-1cdd-48c6-8d54-593faabc5904",
   "metadata": {},
   "source": [
    "回忆上节课的实验\n",
    "\n",
    "- MNIST手写体识别实验，就是 Training\n",
    "- 电影评论情感分类实验，就是 Fine-Tuning\n",
    "\n",
    "Pretraing 代码参考\n",
    "\n",
    "- 不大的模型：以 GPT-2 模型为例\n",
    "  - 第一步：训练 Tokenizer，代码参考：[pretraining/train_tokenizer.py](pretraining/train_tokenizer.py) \n",
    "  - 第二步：预训练模型，代码参考：[pretraining/pretrain_gpt2.py](pretraining/pretrain_gpt2.py)\n",
    "  - 训练条件：8 * A100(40G) GPUs，训练时间约2周\n",
    "- 大语言模型：[OLMo](https://github.com/allenai/OLMo)\n",
    "  - 开源了预训练一个 LLM 的完整过程和数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5361880a-81db-4a92-bc2d-6c9170dbc895",
   "metadata": {},
   "source": [
    "## 九、Transformer 结构简介"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eb67aa-1536-456c-b5be-6d25069c6cb4",
   "metadata": {},
   "source": [
    "Transformer 是组成 LLM 的基本单元。\n",
    "\n",
    "或者说，一个 LLM 就是一个 $N$ 层 Transformer 网络，例如 GPT-3.5 是96层。\n",
    "\n",
    "<img src=\"transformer.gif\" style=\"margin-left: 0px\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a053b5-95ed-419b-9b19-4603dd9f5a3a",
   "metadata": {},
   "source": [
    "### 9.1、Transformer 内部解构简图\n",
    "\n",
    "<img src=\"transformer-block-weights.png\" style=\"margin-left: 0px\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebad980-dffd-4d41-b3aa-6f10be667913",
   "metadata": {},
   "source": [
    "**Self-Attention 的计算**\n",
    "\n",
    "<img src=\"self-attention.png\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "**全连接层：**\n",
    "- 回忆上节课的全连接网络\n",
    "- 这里的激活函数一般是 GELU 或 Swish\n",
    "\n",
    "为了严谨：在 Self-Attention 和全连接网络之间还有个残差和LayerNorm，图中未展示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12186912-6826-4b92-ad8d-a086193b7c9b",
   "metadata": {},
   "source": [
    "### 9.2、LM Head\n",
    "\n",
    "<img src=\"lmhead.png\" style=\"margin-left: 0px\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bc654f-5f35-454a-b0f9-345ed6ad2322",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>扩展阅读：</b> \n",
    "<ul>\n",
    "<li>更详细的Transformer网络拆解（Encoder-Decoder）：https://jalammar.github.io/illustrated-transformer/</li>\n",
    "<li>更详细的GPT模型拆解：https://jalammar.github.io/illustrated-gpt2/</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24831ce9-b44f-4889-8cab-d74fc6d2a132",
   "metadata": {},
   "source": [
    "## 十、轻量化微调\n",
    "\n",
    "<img src=\"peft_process.png\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "- 定义微调数据集加载器\n",
    "- 定义数据处理函数\n",
    "- 加载预训练模型：AutoModel.from_pretrained(MODEL_NAME_OR_PATH)\n",
    "- 在预训练模型上增加任务相关输出层 （如果需要）\n",
    "- 加载预训练 Tokenizer：AutoTokenizer.from_pretrained(MODEL_NAME_OR_PATH)\n",
    "- **定义注入参数的方法（见下文）**\n",
    "- 定义各种超参\n",
    "- 定义 Trainer\n",
    "- 定义 Evaluation Metric\n",
    "- 开始训练\n",
    "\n",
    "### 10.1、Prompt Tuning\n",
    "\n",
    "- 在输入序列前，额外加入一组伪 Embedding 向量\n",
    "- 只训练这组伪 Embedding，从而达到参数微调的效果\n",
    "\n",
    "<img src=\"soft-prompt.png\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "### 10.2、P-Tuning\n",
    "\n",
    "- 用一个生成器生成上述伪 Embedding\n",
    "- 只有生成器的参数是可训练的\n",
    "\n",
    "<img src=\"pt.png\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "### 10.3、Prefix-Tuning\n",
    "\n",
    "- 伪造前面的 Hidden States\n",
    "- 只训练伪造的这个 Prefix\n",
    "\n",
    "<img src=\"pt2.png\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "### 10.4、LoRA\n",
    "\n",
    "- 在 Transformer 的参数矩阵上加一个低秩矩阵（$A\\times B$）\n",
    "- 只训练 A，B\n",
    "- 理论上可以把上述方法应用于 Transformer 中的任意参数矩阵，包括 Embedding 矩阵\n",
    "- 通常应用于 Query, Value 两个参数矩阵\n",
    "\n",
    "<img src=\"lora.png\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "### 10.5、QLoRA\n",
    "\n",
    "什么是模型量化\n",
    "\n",
    "<img src=\"float.png\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "<img src=\"quant.png\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "更多参考: https://huggingface.co/blog/hf-bitsandbytes-integration\n",
    "\n",
    "QLoRA 引入了许多创新来在不牺牲性能的情况下节省显存：\n",
    "\n",
    "- 4位 NormalFloat（NF4），一种对于正态分布权重而言信息理论上最优的新数据类型\n",
    "- 双重量化，通过量化量化常数来减少平均内存占用\n",
    "- 分页优化器，用于管理内存峰值\n",
    "\n",
    "原文实现：单个48G的GPU显卡上微调65B的参数模型，保持16字节微调任务的性能\n",
    "\n",
    "### 10.6、AdaLoRA\n",
    "\n",
    "- 不预先指定可训练矩阵的秩\n",
    "- 根据参数矩阵的重要性得分，在参数矩阵之间自适应地分配参数预算。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b11e8fe-ab3a-4747-8620-5fd80ef9c696",
   "metadata": {},
   "source": [
    "## 十一·、**实战** \n",
    "\n",
    "基于ChatGLM3或Llama2， 微调一个同时具有NLU和问答能力对话机器人\n",
    "\n",
    "### 11.1、数据源\n",
    "\n",
    "酒店预订场景\n",
    "https://github.com/thu-coai/CrossWOZ\n",
    "\n",
    "酒店数据库\n",
    "https://github.com/thu-coai/CrossWOZ/blob/master/data/crosswoz/database/hotel_db.json\n",
    "\n",
    "### 11.2、数据增强\n",
    "\n",
    "- 从CrossWOZ数据集中抽取了只关于酒店的对话\n",
    "- 利用ChatGPT进行如下修改和补充\n",
    "    - 对设施的描述更口语化\n",
    "      - “找一家有国际长途电话的酒店” -> “找一家能打国际长途的酒店”\n",
    "    - 补充一定比例的多轮问答，和结束语对话（p=0.3）\n",
    "      - 针对只提及一个酒店时的问答：“这个酒店的电话是多少”\n",
    "      - 针对推荐多个酒店时的对比问答：“哪个酒店评分更高”\n",
    "      - 结束语：“好的，祝您入住愉快”\n",
    "    - 补充按酒店名（简称）、价格上限查询的对话（原数据中没有这类说法）\n",
    " \n",
    "数据增强的代码参考 [data_augmentation.zip](data_augmentation.zip)\n",
    " \n",
    "最终按8:1:1拆分训练集、验证集和测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1802b7-e38e-47a9-85e4-88ef8f75868c",
   "metadata": {},
   "source": [
    "**原始样本**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846bd2cb-8504-488b-8ad1-d4c1f35acba1",
   "metadata": {},
   "source": [
    "```json\n",
    "[\r\n",
    "    {\r\n",
    "        \"role\": \"user\",\r\n",
    "        \"content\": \"你好，我出差想去酒店住宿。请帮我推荐一家公共区域和部分房间提供wifi服务，评分是4分以上的酒店。\"\r\n",
    "    },\r\n",
    "    {\r\n",
    "        \"role\": \"search\",\r\n",
    "        \"arguments\": {\r\n",
    "            \"facilities\": [\r\n",
    "                \"公共区域和部分房间提供wifi\"\r\n",
    "            ],\r\n",
    "            \"rating_range_lower\": 4.0\r\n",
    "        }\r\n",
    "    },\r\n",
    "    {\r\n",
    "        \"role\": \"return\",\r\n",
    "        \"records\": [\r\n",
    "            {\r\n",
    "                \"name\": \"北京龙鼎华鼎云酒店\",\r\n",
    "                \"type\": \"舒适型\",\r\n",
    "                \"address\": \"北京朝阳区潘家园东里18号\",\r\n",
    "                \"subway\": \"劲松地铁站D口\",\r\n",
    "                \"phone\": \"010-52001188\",\r\n",
    "                \"facilities\": [\r\n",
    "                    \"公共区域和部分房间提供wifi\",\r\n",
    "                    \"宽带上网\",\r\n",
    "                    \"国际长途电话\",\r\n",
    "                    \"吹风机\",\r\n",
    "                    \"24小时热水\",\r\n",
    "                    \"中式餐厅\",\r\n",
    "                    \"会议室\",\r\n",
    "                    \"无烟房\",\r\n",
    "                    \"商务中心\",\r\n",
    "                    \"洗衣服务\",\r\n",
    "                    \"行李寄存\",\r\n",
    "                    \"叫醒服务\"\r\n",
    "                ],\r\n",
    "                \"price\": -1.0,\r\n",
    "                \"rating\": 4.3,\r\n",
    "                \"hotel_id\": 24\r\n",
    "            }\r\n",
    "        ]\r\n",
    "    },\r\n",
    "    {\r\n",
    "        \"role\": \"assistant\",\r\n",
    "        \"content\": \"那您去北京龙鼎华鼎云酒店住宿吧，酒店质量很好。\"\r\n",
    "    }\r\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6eb348-8d7c-41e3-a94b-9fd3376f9d54",
   "metadata": {},
   "source": [
    "**增强后样本**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31149d83-2bb1-4d38-8d01-5d47ffd22e88",
   "metadata": {},
   "source": [
    "```json\n",
    "[\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"你好，我出差想去酒店住宿。请帮我推荐一家提供无线网络且评分在4分以上的酒店。\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"search\",\n",
    "        \"arguments\": {\n",
    "            \"facilities\": [\n",
    "                \"无线网络\"\n",
    "            ],\n",
    "            \"rating_range_lower\": 4.0\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"return\",\n",
    "        \"records\": [\n",
    "            {\n",
    "                \"name\": \"北京龙鼎华鼎云酒店\",\n",
    "                \"type\": \"舒适型\",\n",
    "                \"address\": \"北京朝阳区潘家园东里18号\",\n",
    "                \"subway\": \"劲松地铁站D口\",\n",
    "                \"phone\": \"010-52001188\",\n",
    "                \"facilities\": [\n",
    "                    \"公共区域和部分房间提供wifi\",\n",
    "                    \"宽带上网\",\n",
    "                    \"国际长途电话\",\n",
    "                    \"吹风机\",\n",
    "                    \"24小时热水\",\n",
    "                    \"中式餐厅\",\n",
    "                    \"会议室\",\n",
    "                    \"无烟房\",\n",
    "                    \"商务中心\",\n",
    "                    \"洗衣服务\",\n",
    "                    \"行李寄存\",\n",
    "                    \"叫醒服务\"\n",
    "                ],\n",
    "                \"price\": -1.0,\n",
    "                \"rating\": 4.3,\n",
    "                \"hotel_id\": 24\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"那您去北京龙鼎华鼎云酒店住宿吧，酒店质量很好。\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"这个酒店的评分是多少？\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"这个酒店的评分是4.3分。\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"好的，我决定入住北京龙鼎华鼎云酒店了。\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"好的，祝您入住愉快。\"\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdadb9dc-982d-4183-b691-40946115511d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 11.3、数据的基本拼接方式\n",
    "\n",
    "<img src=\"batch.png\" width=400px/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ce074b-9af5-4e4b-a73d-7dc727ee27a5",
   "metadata": {},
   "source": [
    "### 11.4、多轮对话怎么拼\n",
    "\n",
    "### **方法一**：ChatGLM 2 的方式"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2cf0ca1c-b843-4c34-af0c-766e910b8320",
   "metadata": {},
   "source": [
    "user: 你好\n",
    "assistant: 有什么可以帮您\n",
    "user: 你喜欢什么颜色\n",
    "assistant: 喜欢黑色\n",
    "user: 为什么\n",
    "assistant: 因为黑色幽默"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cdc47c-d8b6-419e-bbd3-a7030546f3d7",
   "metadata": {},
   "source": [
    "按照轮次，上述对话将被拆分成3个单独的样本\n",
    "- 每个样本以之前的历史为输入\n",
    "- 当前轮的回复为输出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cb958b-eba3-4322-9ab9-fa579b55d439",
   "metadata": {},
   "source": [
    "<span style=\"color:green\"><b>样本1</b></span>\n",
    "\n",
    "输入：\n",
    "\\[Round 0\\]\\\\n\n",
    "问: 你好\\\\n\n",
    "答: \n",
    "\n",
    "输出：\n",
    "有什么可以帮您\n",
    "\n",
    "<span style=\"color:green\"><b>样本2</b></span>\n",
    "\n",
    "输入：\n",
    "\\[Round 0\\]\\\\n\n",
    "问: 你好\\\\n\n",
    "答: 有什么可以帮您\\\\n\n",
    "\\[Round 1\\]\\\\n\n",
    "问: 你喜欢什么颜色\\\\n\n",
    "答:\n",
    "\n",
    "输出：\n",
    "喜欢黑色\n",
    "\n",
    "<span style=\"color:green\"><b>样本3</b></span>\n",
    "\n",
    "输入：\n",
    "\\[Round 0\\]\\\\n\n",
    "问: 你好\\\\n\n",
    "答: 有什么可以帮您\\\\n\n",
    "\\[Round 1\\]\\\\n\n",
    "问: 你喜欢什么颜色\\\\n\n",
    "答: 喜欢黑色\\\\n\n",
    "问: 为什么\\\\n\n",
    "答:\n",
    "\n",
    "输出：\n",
    "因为黑色幽默"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bbedb7-6fb7-4caa-b0b5-9ce3b0ab4c8b",
   "metadata": {},
   "source": [
    "### **方法二**：ChatGLM 3 的方式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf019205-4aa2-4a8f-bc38-10fb5202b250",
   "metadata": {},
   "source": [
    "因为CausalLM是一直从左往右预测的，我们可以直接在多轮对话中标识出多段输出。具体如下：\n",
    "\n",
    "角色**special token**用于标识分隔出多轮对话，同时也可以防范注入攻击\n",
    "\n",
    " - <|system|>      #系统提示词，指明模型可使用的工具等信息\n",
    " - <|user|>        #用户输入，用户的指令\n",
    " - <|assistant|>   #模型回复，或模型思考要做的事情\n",
    " - <|observation|> #工具调用、代码执行结果\n",
    "\n",
    "注意：**这里<|role|>这种是一个token**，而不是一串文本，所以不能通过`tokenizer.encode('<role>')`来得到\n",
    "\n",
    "角色后跟随的是metadata，对于function calling来说，metadata是调用的函数和相应参数；对其他角色的对话，metadata为空\n",
    "\n",
    "- 多轮对话finetune时根据角色添加loss_mask\n",
    "- 在一遍计算中为多轮回复计算loss\n",
    "\n",
    "---\n",
    "\n",
    "<|system|>Answer the following questions as best as you can. \n",
    "\n",
    "You have access to the following tools:\\n[...]\n",
    "\n",
    "<|user|>\\n北京的天气怎么样？\n",
    "\n",
    "<|assistant|><span style=\"background-color: yellow; color: black;\">\\n我需要调用天气预报工具来获取北京的天气信息。</span>\n",
    "\n",
    "<span style=\"background-color: yellow; color: brown;\"><|assistant|>get_weather\\n\\`\\`\\`python\\ntool_call(location=\"北京\")\\`\\`\\`</span>\n",
    "\n",
    "<span style=\"background-color: yellow; color: black;\"><|observation|>\\n</span>{\"temperature_c\": 12, \"description\": \"haze\"}\n",
    "\n",
    "<|assistant|><span style=\"background-color: yellow; color: black;\">\\n根据天气工具的信息，北京的天气是：温度 12 摄氏度，有雾。</span>\n",
    "\n",
    "<span style=\"background-color: yellow; color: black;\"><|user|></span>\\n这样的天气适合外出活动吗？\n",
    "\n",
    "<|assistant|><span style=\"background-color: yellow; color: black;\">\\n北京现在有雾，气温较低，建议您考虑一下是否适合外出进行锻炼。</span>\n",
    "\n",
    "<span style=\"background-color: yellow; color: black;\"><|user|></span>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "高亮部分为需要计算loss的token。**注意<|assistant|＞后的内容和角色token都需要算loss。**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51a9673-ffff-44f3-afa0-1acaada8d49e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>参考：</b> \n",
    "<ul>\n",
    "<li>官方讲解：https://www.bilibili.com/video/BV1uC4y1J7yA</li>\n",
    "<li>数据格式部分约在 17'30\"</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba96263-13f8-44d4-8bfc-e1d589b0358c",
   "metadata": {},
   "source": [
    "### 11.4.1、ChatGLM 3 的数据加载"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058b5170-7b3b-49be-9f87-73a9acbd5f56",
   "metadata": {},
   "source": [
    "实际应用中，我们只需要将上述数据，与ChatGLM 3的标准数据格式对齐，就可调用其原生的数据加载器，自动完成数据拼接\n",
    "\n",
    "ChatGLM 3原生的数据加载器代码：https://github.com/THUDM/ChatGLM3/blob/main/finetune_chatmodel_demo/preprocess_utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe94a29-fc3c-49a6-878e-766ef037ee55",
   "metadata": {},
   "source": [
    "**格式化后的数据样例**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3484afa-8997-4006-aa1c-793a7703eb77",
   "metadata": {},
   "source": [
    "```json\n",
    "{\n",
    "  \"tools\": [\n",
    "    \"search_hotels: 根据筛选条件查询酒店的函数\\nparameters: {\\\"name\\\":\\\"酒店名称\\\",\\\"price_range_lower\\\":\\\"价格下限\\\",\\\"price_range_upper\\\":\\\"价格上限\\\",\\\"rating_range_lower\\\":\\\"评分下限\\\",\\\"rating_range_upper\\\":\\\"评分上限\\\",\\\"facilities\\\": \\\"酒店提供的设施\\\"}\\noutput: 酒店信息dict组成的list\"\n",
    "  ],\n",
    "  \"conversations\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"请帮我找一家最低价格是300-400元，提供无烟房的经济型酒店。\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"我需要使用search_hotels工具来查询酒店\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"tool\",\n",
    "      \"name\": \"search_hotels\",\n",
    "      \"parameters\": {\n",
    "        \"facilities\": [\n",
    "          \"无烟房\"\n",
    "        ],\n",
    "        \"price_range_lower\": 300,\n",
    "        \"price_range_upper\": 400,\n",
    "        \"type\": \"经济型\"\n",
    "      },\n",
    "      \"observation\": [\n",
    "        {\n",
    "          \"name\": \"飘HOME连锁酒店(北京王府井店)\",\n",
    "          \"type\": \"经济型\",\n",
    "          \"address\": \"北京东城区东安门大街43号\",\n",
    "          \"subway\": \"灯市口地铁站A口\",\n",
    "          \"phone\": \"010-57305888\",\n",
    "          \"facilities\": [\n",
    "            \"酒店各处提供wifi\",\n",
    "            \"宽带上网\",\n",
    "            \"吹风机\",\n",
    "            \"24小时热水\",\n",
    "            \"暖气\",\n",
    "            \"无烟房\",\n",
    "            \"早餐服务\",\n",
    "            \"行李寄存\",\n",
    "            \"叫醒服务\"\n",
    "          ],\n",
    "          \"price\": 303.0,\n",
    "          \"rating\": 4.3,\n",
    "          \"hotel_id\": 152\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"推荐您去飘HOME连锁酒店(北京王府井店)。\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8b2fc7-973f-4afc-b3ad-6a6267c6ad62",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>划重点：</b> \n",
    "    <ol>\n",
    "        <li>在 tools 字段中描述function和parameters的定义</li>\n",
    "        <li>在 conversations 字段中组织对话轮次</li>\n",
    "        <li>以 user 和 assistant 标识出用户输入与系统回复</li>\n",
    "        <li>在 function call 的角色以 tool 标识，并填入 function 名称和参数</li>\n",
    "        <li>以 observation 标识出 function 的返回结果</li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b9846e-e5b2-4b5f-8a98-4306b7470c67",
   "metadata": {},
   "source": [
    "### 11.5、如何在 Llama 2 中实现类似 Function Calling 的效果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668f8541-63a9-46b6-8a8f-4cc476ac9064",
   "metadata": {},
   "source": [
    "参考 ChatGLM 2 的实现方式\n",
    "\n",
    "1. 我们自定义user、assistant、search、return四个前缀。\n",
    "   - 因为只有一个 function，我们直接把 function 标识成 search\n",
    "2. 每轮 assistant 和 search 前缀也由模型自动生成，我们以此判断是 function 还是文本回复\n",
    "3. 类似 ChatGLM 2，我们以“\\[Round $i$\\]\\n\\n”标识轮数 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e900b7-bd7f-48f7-90ec-770b77df1060",
   "metadata": {},
   "source": [
    "#### **Function Call 的样例**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec3df79-effe-432d-a7ea-7a5cb5897e42",
   "metadata": {},
   "source": [
    "**输入** \n",
    "\n",
    "\\[Round 0\\]\n",
    "\n",
    "user:  你好，请帮我推荐一个提供无烟房的舒适型酒店可以吗？\n",
    "\n",
    " **输出**\n",
    "\n",
    " search: {\\\"facilities\\\": \\[\\\"无烟房\\\"\\], \\\"type\\\": \\\"舒适型\\\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c25a72-3502-4cd9-bf27-d73ef45042d4",
   "metadata": {},
   "source": [
    "#### **文本回复的样例**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d23171-f8c3-4402-a9e7-7fb684c107a4",
   "metadata": {},
   "source": [
    "**输入** \n",
    "\n",
    "\\[Round 0\\]\n",
    "\n",
    "user: 你好，请帮我推荐一个提供无烟房的舒适型酒店可以吗？\n",
    "\n",
    "search: {\\\"facilities\\\": \\[\\\"无烟房\\\"\\], \\\"type\\\": \\\"舒适型\\\"}}\n",
    "\n",
    "\\[Round 1\\]\n",
    "\n",
    "return: \\[{\\\"name\\\": \\\"北京红驿栈酒店\\\", \\\"type\\\": \\\"舒适型\\\", \\\"address\\\": \\\"北京朝阳区东直门外春秀路太平庄10号(主副楼在一幢建筑里)\\\", \\\"subway\\\": \\\"东直门地铁站E口\\\", \\\"phone\\\": \\\"010-64171066\\\", \\\"facilities\\\": \\[\\\"公共区域和部分房间提供wifi\\\", \\\"宽带上网\\\", \\\"国际长途电话\\\", \\\"吹风机\\\", \\\"24小时热水\\\", \\\"暖气\\\", \\\"无烟房\\\", \\\"早餐服务\\\", \\\"接待外宾\\\", \\\"行李寄存\\\", \\\"叫醒服务\\\"\\], \\\"price\\\": 344.0, \\\"rating\\\": 4.7, \\\"hotel_id\\\": 51}, {\\\"name\\\": \\\"维也纳国际酒店(北京广安门店)\\\", \\\"type\\\": \\\"舒适型\\\", \\\"address\\\": \\\"北京西城区白广路7号\\\", \\\"subway\\\": \\\"广安门内地铁站C口\\\", \\\"phone\\\": \\\"010-83539988\\\", \\\"facilities\\\": \\[\\\"酒店各处提供wifi\\\", \\\"宽带上网\\\", \\\"吹风机\\\", \\\"24小时热水\\\", \\\"中式餐厅\\\", \\\"会议室\\\", \\\"无烟房\\\", \\\"商务中心\\\", \\\"早餐服务\\\", \\\"洗衣服务\\\", \\\"行李寄存\\\", \\\"叫醒服务\\\"\\], \\\"price\\\": 553.0, \\\"rating\\\": 4.7, \\\"hotel_id\\\": 56}\\]}\\]\n",
    "\n",
    "**输出** \n",
    "\n",
    "assistant: 没问题，推荐你去北京红驿栈酒店和维也纳国际酒店(北京广安门店)，都挺好的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c9e889-16aa-4dde-84e3-25735477e4b9",
   "metadata": {},
   "source": [
    "### 11.6、编写训练代码\n",
    "\n",
    "**见附件: [fine-tuning-lab-v3.zip](fine-tuning-lab-v3.zip)**\n",
    "\n",
    "### 11.7、训练后，在测试集上的参考指标\n",
    "\n",
    "1. 针对 Function Calling 的每个参数（即 Slot），我们评估准确率、召回率、F1值\n",
    "2. 针对文本回复，我们评估输出文本与参考文本之间的 BLEU Score\n",
    "3. 如果本该是 Function Calling 的轮次，模型回复了文本，则所有指标为 0，反之 BLEU Score 为 0\n",
    "\n",
    "| Model       | Method      | BLEU-4 | SLOT-P | SLOT-R | SLOT-F1 | \n",
    "| :---------- | :---------- | :----: | :-----: | :-----: | :-----: | \n",
    "| ChatGLM3-6B | 原生 | 14.41 |  64.97 | 36.98 |  47.13  |   \n",
    "|  | P-Tuning V2 | 61.68 |  94.51 |  91.47  |  92.97  |   \n",
    "|             | LoRA        | **66.62**  |  **95.91**  |  94.21  |  **95.05**  |   \n",
    "| Llama2-7B | QLoRA | 63.18 | 95.29 |  **94.53**  |  94.91  | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b8772d-ddcb-419b-96bd-463a2e6c2dd7",
   "metadata": {},
   "source": [
    "## 十二、数据准备与处理\n",
    "\n",
    "### 12.1、数据采集\n",
    "\n",
    "- 自然来源（如业务日志）：真实数据\n",
    "- Web 抓取：近似数据\n",
    "- 人造\n",
    "\n",
    "### 12.2、数据标注\n",
    "\n",
    "- 专业标注公司\n",
    "  - 定标准，定验收指标\n",
    "  - 预标注\n",
    "  - 反馈与优化\n",
    "  - 正式标注\n",
    "  - 抽样检查：合格->验收；不合格->返工\n",
    "- 众包\n",
    "  - 定标准，定检验指标\n",
    "  - 抽样每个工作者的质量\n",
    "  - 维系高质量标注者社区\n",
    "- 主动学习：通过模型选择重要样本，由专家标注，再训练模型\n",
    "- 设计产品形态，在用户自然交互中产生标注数据（例如点赞、收藏）\n",
    "\n",
    "### 12.3、数据清洗\n",
    "\n",
    "- 去除不相关数据\n",
    "- 去除冗余数据（例如重复的样本）\n",
    "- 去除误导性数据（业务相关）\n",
    "\n",
    "### 12.4、样本均衡性\n",
    "\n",
    "- 尽量保证每个标签（场景/子问题）都有足够多的训练样本\n",
    "- 每个标签对应的数据量尽量相当\n",
    "  - 或者在保证每个标签样本充值的前提下，数据分布尽量接近真实业务场景的数据分布\n",
    "- 数据不均衡时的策略\n",
    "  - 数据增强：为数据不够类别造数据：（1）人工造；（2）通过模板生成再人工标注；（3）由模型自动生成（再人工标注/筛选）\n",
    "  - 数据少的类别数据绝对数量也充足时，Downsample 一般比 Upsample 效果好\n",
    "  - 实在没办法的话，在训练 loss 里加权（一般不是最有效的办法）\n",
    "- 根据业务属性，保证其他关键要素的数据覆盖，例如：时间因素、地域因素、用户年龄段等\n",
    "\n",
    "### 12.5、数据集构建\n",
    "\n",
    "- 数据充分的情况下\n",
    "  - 切分训练集（训练模型）、验证集（验证超参）、测试集（检验最终模型+超参的效果）\n",
    "  - 以随机采样的方式保证三个集合的数据分布一致性\n",
    "  - 在以上三个集合里都尽量保证各个类别/场景的数据覆盖\n",
    "- 数据实在太少\n",
    "  - 交叉验证\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa23923-43e3-405f-95a6-d8d2a11934c6",
   "metadata": {},
   "source": [
    "## 作业：训练自己的模型\n",
    "\n",
    "请跟随[实验指导](lab/index.ipynb)完成本次作业。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
