## LLM优点

总结、推理、转换、扩展

## LLM弱点

即使模型训练过程中会学习大量知识，但它并不会完全记住它所看到的信息，所以它并不非常清楚知识的边界，于是它会尝试回答问题，并编造看起来合理，但是实际上并不正确的内容。 这些虚构的想法，我们称为**幻觉（hallucination）**

> 给模型一个边界，例如要求模型从确切文档中进行回答，可以有效减少幻觉

## 提示指南

1. 编写明确和具体的指令
  * 例如可以使用`【】`来包裹关键指令
  * 可以要求模型结构化输出：`JSON、html`等
  * 要求模型检查是否满足条件
  * 少量提示训练，在执行任务之前先向模型提供任务成功的示例
2. 给模型足够的时间来思考
  * 给模型指定完成任务所需的步骤

## 提示迭代

并不是所有的提示都适合所有的应用程序（接入了模型的应用），需要找到适合的提示。

迭代的过程就是提示内容优化的过程。不同的应用程序需要对外输出的内容其实是不一样的，所以需要迭代提示来优化输出内容。

例如：内容是否太长，是否缺少某些信息，是否需要简化。

## 提示摘要

简单要求模型对文章进行总结，有适合并不能得到我们想要的文章概要

如何准确的提示摘要：

* 要求模型总结具体信息，例如【时间、地点、人物】
* 要求模型提取某些相关信息，例如【获取与位置相关的信息】
* 告诉模型这个摘要是用来做什么的？例如【提供给政府的报告】

## 提示推理

任何需要通过文章内容进行推理的问题，都可以直接交给模型进行推理。

* 可以让模型进行推理，例如 【下述文章中表达了怎样的情感】
* 可以让模型推理文章是关于什么的？例如【输出下述文章中的五个主题】

## 提示转换

对输入进行格式、语气、情感、对象等信息的转换

* 翻译
* 格式转换，例如【2023/2/02转换成短横杠分隔】【将下述json内容转换成html】
* 语气转换，例如【把这篇写给我父亲的文章转换成写给我朋友的】【使用书面语言修复这篇文章】

## 提示扩展

基于输入生成，邮件、文章、评论等

例如【请使用简明和专业的语气，对下述文章进行评论，并对文章的作者表示感谢】

### 温度

模型参数之一：**温度（temperature）**，代表模型的探索程度或者随机性；

假设，特定词【我最喜爱的食物是】，模型预测下一个词有可能是披萨（50%），寿司（30%），馒头（5%），那么：

* 温度为0时，每次返回的都是披萨
* 温度为0.3时，返回的可能是披萨、寿司
* 温度为0.7时，返回的可能是披萨、寿司、馒头

如果我们想构建一个可靠和可预测的系统，我们应当始终使温度参数为0

如果想要更有创意，更广泛，则使用更大的温度参数。

温度的修改方式是修改API调用中的参数。

## 聊天机器人

将一系列消息作为输入，将模型生成的消息作为输出

系统消息（system）：用于设置助手的行为和人设,作为高层指令与助手。用户察觉不到。可以再这里给助手进行完整的指示，例如【你是一个和蔼的老太太，你喜欢问别人吃了么？当别人说吃了的时候，你就问吃饱没有？】
助手消息（assistant）：chatgpt
用户消息（user）：我

如果需要使用上下文，我们可以采取append消息的方式

## 如何完成提示通用 

通过API调用模型接口，对来自用户的输入，添加提示词来达到通用提示效果
```js
  cosnt str = `输出文章中的时间、地点、人物, 文章使用【】包裹。\n【${'用户的输入'}】`
```

## 应用场景

综上所述，LLM的应用场景至少包括：

* 控评。快速优化评论区，无需人工逐个审查
  > 使用模型快速判断评论情绪，是否拥有负面情绪
* 概要。快速生成文章概要。
* 客服
* 助手