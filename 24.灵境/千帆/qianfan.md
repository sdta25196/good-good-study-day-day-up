# 千帆


## 基于API应用开发模式

1. 【AI端】调用API接口（几行代码/Python语言），可通过Prompt设计引入相关知识（无需修改模型的结构或参数）
2. 【前端】写web端/移动端界面、交互（html/css/js/gradio/streamlit）
3. 【后端】整体任务逻辑/队列、集成和调用AI端能力、返回AI端结果

所需能力：无需有AI算法能力，需有前后端开发和工程落地能力

总结：AI部分难度较小，无需AI专业知识，主要开发工作在前后端和工程化落地。


## 基于大模型的微调应用开发模式

### Fine-tuning

1. 【AI端】加载已经预训练好的大模型，准备和上传训练数据（与目标任务相关的数据，符合fine-tuning文件格式），训练新的Fine-tuning模型，也可以加入一些分类层等；模型封装和部署：高性能/高并发/高可用
  a. 【数据】数据获取，仿照给定数据示例构建新的数据集（字段：Prompt-Completion）
2. 【前端】写web端/移动端界面、交互逻辑（html/css/js/gradio/streamlit）
3. 【后端】整体任务逻辑/队列、集成和调用AI端能力、返回AI端结果

所需能力：深度学习算法原理、跨模态数据处理、模型训练、模型部署/弹性部署；前后端开发和工程落地

总结：
1. AI部分难度较大，需懂深度学习原理，会数据处理（跨模态数据融合），会训练模型；算力资源消耗大。
2. 难点主要在于数据工程（数据采集、清洗、对齐）和训练推理资源。
3. 随着模型规模增大，效果提升逐渐饱和。

### Prompt-tuning

1. 【AI端】设计预训练语言模型的任务、设计输入模板样式(Prompt Engineering)、设计label 样式及模型的输出映射到label的方式(Answer Engineering)，prompt-completion-label；
  a. 【数据】标签数据准备、Verbalizer准备、prompt模板设定
2. 【前端】写web端/移动端界面、交互逻辑
3. 【后端】整体任务逻辑/队列、集成和调用AI端能力、返回AI端结果

所需能力：Prompt engineering相关技巧、前后端开发和工程落地

总结：无需数据标注，难点在于Prompt模板设计（人工设计模板/自动学习模板），需要根据下游任务和预训练模型的特性来选择合适的模板，微调消耗的存储和运算资源相比传统finetune有所降低。


## 基于大模型API或大模型微调+插件开发模式

**这种方式更适合我们。**

将垂直行业的领域知识向量化并存入向量数据库——用户提问——用户问题向量化——查询向量数据库，得到TopN条匹配知识——构建Prompt，调用 API——返回回答.

例如：向量知识库embedding

总结：AI部分难度较小，难点在于整体任务流程的工程化思考和落地。对任务流程拆解的工程化思考要求较高（节点/队列流程设计、弹性部署等）

## 相关链接 

[基于大模型的应用开发方式介绍](https://cloud.baidu.com/qianfandev/topic/267755)

[如何准备用于微调的数据集](https://cloud.baidu.com/qianfandev/topic/267759)

[基于文心大模型开发的应用在应用商店/微信小程序上架指南](https://cloud.baidu.com/qianfandev/topic/267218)



## 名词解释 

SFT：这是Selective Fine-tuning的缩写，被翻译为选择性精调。这是一种模型训练策略，在预训练模型的基础上，选择性地对部分参数进行精细调整，以适应特定的任务。这样可以在保留模型在大规模数据上训练得到的通用知识的同时，提升模型在特定任务上的性能。

Post-pretrain：也被称为后期预训练或者模型微调，通常是指在一个预训练模型（已在大量数据上进行过训练）的基础上，进行进一步的训练或优化，以适应特定任务或特定数据。

RLHF：这可能是指Reinforcement Learning with Human Feedback的缩写，即通过人类反馈进行强化学习的过程。在这一过程中，人类反馈被用作奖励信号，以指导模型进行学习和优化。


## 千帆工作流程

  * 数据导入
  * 数据标注
  * 训练配置
  * 模型纳管
  * 发布服务
  * 体验测试

# 工作安排

*  按照流程跑一遍千帆
*  各种插件测试一遍
*  搞定价钱
*  知识库 + 模型就可以做智能问答？ 搞个知识库


